{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923e1ba3-d717-45e4-9b5c-062bcdf05754",
   "metadata": {},
   "source": [
    "# **Exercise 2.4: Evaluating Hyperparameters. Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9be420-18bb-43f1-9b16-497fab5bfc3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d5bf7df6-2a6a-425d-b69c-1d6fe0b68269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7174a9-84b4-4e52-acbe-9428ea44f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Nuria Miquel\\Desktop\\nuria\\Machine Learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae43e53-a6be-4792-a3d8-70e4da92a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'Data', 'Prepared Data', 'weather_cleaned2.csv'), index_col = False)\n",
    "pleasant = pd.read_csv(os.path.join(path, 'Data', 'Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b3e6bf-7db4-4f80-af34-a9a6a82d842a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  \\\n",
       "0  19600101                  7            0.85           1.018   \n",
       "1  19600102                  6            0.84           1.018   \n",
       "2  19600103                  8            0.90           1.018   \n",
       "3  19600104                  3            0.92           1.018   \n",
       "4  19600105                  6            0.95           1.018   \n",
       "\n",
       "   BASEL_global_radiation  BASEL_precipitation  BASEL_sunshine  \\\n",
       "0                    0.32                 0.09             0.7   \n",
       "1                    0.36                 1.05             1.1   \n",
       "2                    0.18                 0.30             0.0   \n",
       "3                    0.58                 0.00             4.1   \n",
       "4                    0.65                 0.14             5.4   \n",
       "\n",
       "   BASEL_temp_mean  BASEL_temp_min  BASEL_temp_max  ...  STOCKHOLM_temp_max  \\\n",
       "0              6.5             0.8            10.9  ...                 4.9   \n",
       "1              6.1             3.3            10.1  ...                 5.0   \n",
       "2              8.5             5.1             9.9  ...                 4.1   \n",
       "3              6.3             3.8            10.6  ...                 2.3   \n",
       "4              3.0            -0.7             6.0  ...                 4.3   \n",
       "\n",
       "   VALENTIA_cloud_cover  VALENTIA_humidity  VALENTIA_pressure  \\\n",
       "0                     5               0.88             1.0003   \n",
       "1                     7               0.91             1.0007   \n",
       "2                     7               0.91             1.0096   \n",
       "3                     7               0.86             1.0184   \n",
       "4                     3               0.80             1.0328   \n",
       "\n",
       "   VALENTIA_global_radiation  VALENTIA_precipitation  VALENTIA_sunshine  \\\n",
       "0                       0.45                    0.34                4.7   \n",
       "1                       0.25                    0.84                0.7   \n",
       "2                       0.17                    0.08                0.1   \n",
       "3                       0.13                    0.98                0.0   \n",
       "4                       0.46                    0.00                5.7   \n",
       "\n",
       "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
       "0                 8.5                6.0               10.9  \n",
       "1                 8.9                5.6               12.1  \n",
       "2                10.5                8.1               12.9  \n",
       "3                 7.4                7.3               10.6  \n",
       "4                 5.7                3.0                8.4  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70031fbe-5c38-4644-a11e-adb2943f1ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0  19600101                       0                          0   \n",
       "1  19600102                       0                          0   \n",
       "2  19600103                       0                          0   \n",
       "3  19600104                       0                          0   \n",
       "4  19600105                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7905f465-74d2-4658-945d-82ac38ef97b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06b54a45-7a9c-438c-b815-5a9b2848bf11",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DATE'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m pleasant\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DATE'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop('DATE', inplace = True)\n",
    "pleasant.drop('DATE', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d1b953f-8f4f-4500-99f5-65606847a1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>...</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  BASEL_global_radiation  \\\n",
       "0                  7            0.85           1.018                    0.32   \n",
       "1                  6            0.84           1.018                    0.36   \n",
       "2                  8            0.90           1.018                    0.18   \n",
       "3                  3            0.92           1.018                    0.58   \n",
       "4                  6            0.95           1.018                    0.65   \n",
       "\n",
       "   BASEL_precipitation  BASEL_sunshine  BASEL_temp_mean  BASEL_temp_min  \\\n",
       "0                 0.09             0.7              6.5             0.8   \n",
       "1                 1.05             1.1              6.1             3.3   \n",
       "2                 0.30             0.0              8.5             5.1   \n",
       "3                 0.00             4.1              6.3             3.8   \n",
       "4                 0.14             5.4              3.0            -0.7   \n",
       "\n",
       "   BASEL_temp_max  BELGRADE_cloud_cover  ...  STOCKHOLM_temp_max  \\\n",
       "0            10.9                     1  ...                 4.9   \n",
       "1            10.1                     6  ...                 5.0   \n",
       "2             9.9                     6  ...                 4.1   \n",
       "3            10.6                     8  ...                 2.3   \n",
       "4             6.0                     8  ...                 4.3   \n",
       "\n",
       "   VALENTIA_cloud_cover  VALENTIA_humidity  VALENTIA_pressure  \\\n",
       "0                     5               0.88             1.0003   \n",
       "1                     7               0.91             1.0007   \n",
       "2                     7               0.91             1.0096   \n",
       "3                     7               0.86             1.0184   \n",
       "4                     3               0.80             1.0328   \n",
       "\n",
       "   VALENTIA_global_radiation  VALENTIA_precipitation  VALENTIA_sunshine  \\\n",
       "0                       0.45                    0.34                4.7   \n",
       "1                       0.25                    0.84                0.7   \n",
       "2                       0.17                    0.08                0.1   \n",
       "3                       0.13                    0.98                0.0   \n",
       "4                       0.46                    0.00                5.7   \n",
       "\n",
       "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
       "0                 8.5                6.0               10.9  \n",
       "1                 8.9                5.6               12.1  \n",
       "2                10.5                8.1               12.9  \n",
       "3                 7.4                7.3               10.6  \n",
       "4                 5.7                3.0                8.4  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "961cb2ea-5d3c-4ddb-a3a5-13056e1c2315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0                       0                          0   \n",
       "1                       0                          0   \n",
       "2                       0                          0   \n",
       "3                       0                          0   \n",
       "4                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9b402b3-8d8b-4a33-a922-bfa5708cc24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950, 135)\n",
      "(22950, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(pleasant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdce885-0b34-4f0a-81b7-2faaea7ae999",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4100679d-3db7-48d0-a55f-7b9ff2468474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df)\n",
    "y = np.array(pleasant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e06eded4-ffeb-46de-94ae-137dbd9f8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,15,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1b2995d7-61a3-4c7c-a7f1-95125e2e3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  np.argmax(y, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "740f5aeb-03ef-4ee4-b857-adf62cee2290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950, 15, 9)\n",
      "(22950,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0b555f89-57c1-4fb8-aae4-90c86fe1e386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Bayesian optimization function only accepts y data in “multiclass” and “binary” layouts but not in “multilabel-indicator.”\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936f0cf-f268-468c-81c4-cb00c355bbc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d993794e-b36e-4a80-864d-f96db96799b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c07e483c-3da1-41fd-ba33-28919186f526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17212, 15, 9) (17212,)\n",
      "(5738, 15, 9) (5738,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8bdb8f-922a-4410-bf84-05d39de1cf44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ad33855-a260-4ae6-988a-d50e12725d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 \n",
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d31ba8fb-20e7-49e0-bcf7-102a35c09c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    #optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 #'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 #'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 #'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]  #optimizerD[optimizerL[round(optimizer)]]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c677a4da-51e4-48ac-a342-6acb36b205ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/23\n",
      "29/29 - 5s - 160ms/step - accuracy: 0.6255 - loss: 2.7018\n",
      "Epoch 2/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6440 - loss: 2.6959\n",
      "Epoch 3/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6909\n",
      "Epoch 4/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6867\n",
      "Epoch 5/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6831\n",
      "Epoch 6/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6797\n",
      "Epoch 7/23\n",
      "29/29 - 1s - 24ms/step - accuracy: 0.6440 - loss: 2.6766\n",
      "Epoch 8/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6737\n",
      "Epoch 9/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6708\n",
      "Epoch 10/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6440 - loss: 2.6681\n",
      "Epoch 11/23\n",
      "29/29 - 1s - 28ms/step - accuracy: 0.6440 - loss: 2.6654\n",
      "Epoch 12/23\n",
      "29/29 - 1s - 29ms/step - accuracy: 0.6440 - loss: 2.6626\n",
      "Epoch 13/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6599\n",
      "Epoch 14/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6570\n",
      "Epoch 15/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6540\n",
      "Epoch 16/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6507\n",
      "Epoch 17/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6472\n",
      "Epoch 18/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6434\n",
      "Epoch 19/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6392\n",
      "Epoch 20/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6440 - loss: 2.6345\n",
      "Epoch 21/23\n",
      "29/29 - 1s - 30ms/step - accuracy: 0.6440 - loss: 2.6292\n",
      "Epoch 22/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6232\n",
      "Epoch 23/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6440 - loss: 2.6165\n",
      "8/8 - 0s - 43ms/step\n",
      "Epoch 1/23\n",
      "29/29 - 4s - 132ms/step - accuracy: 0.6239 - loss: 2.7002\n",
      "Epoch 2/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6959\n",
      "Epoch 3/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6909\n",
      "Epoch 4/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6867\n",
      "Epoch 5/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6830\n",
      "Epoch 6/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6797\n",
      "Epoch 7/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6766\n",
      "Epoch 8/23\n",
      "29/29 - 1s - 28ms/step - accuracy: 0.6440 - loss: 2.6736\n",
      "Epoch 9/23\n",
      "29/29 - 1s - 29ms/step - accuracy: 0.6440 - loss: 2.6707\n",
      "Epoch 10/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6679\n",
      "Epoch 11/23\n",
      "29/29 - 1s - 31ms/step - accuracy: 0.6440 - loss: 2.6652\n",
      "Epoch 12/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6624\n",
      "Epoch 13/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6595\n",
      "Epoch 14/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6565\n",
      "Epoch 15/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6533\n",
      "Epoch 16/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6498\n",
      "Epoch 17/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6460\n",
      "Epoch 18/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6418\n",
      "Epoch 19/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6371\n",
      "Epoch 20/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6319\n",
      "Epoch 21/23\n",
      "29/29 - 1s - 28ms/step - accuracy: 0.6440 - loss: 2.6259\n",
      "Epoch 22/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6192\n",
      "Epoch 23/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6116\n",
      "8/8 - 0s - 38ms/step\n",
      "Epoch 1/23\n",
      "29/29 - 4s - 140ms/step - accuracy: 0.6224 - loss: 2.7029\n",
      "Epoch 2/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6959\n",
      "Epoch 3/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6909\n",
      "Epoch 4/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6868\n",
      "Epoch 5/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6831\n",
      "Epoch 6/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6797\n",
      "Epoch 7/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6766\n",
      "Epoch 8/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6737\n",
      "Epoch 9/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6708\n",
      "Epoch 10/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6681\n",
      "Epoch 11/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6653\n",
      "Epoch 12/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6626\n",
      "Epoch 13/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6598\n",
      "Epoch 14/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6570\n",
      "Epoch 15/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6540\n",
      "Epoch 16/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6508\n",
      "Epoch 17/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6474\n",
      "Epoch 18/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6439 - loss: 2.6437\n",
      "Epoch 19/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6397\n",
      "Epoch 20/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6352\n",
      "Epoch 21/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6302\n",
      "Epoch 22/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6439 - loss: 2.6246\n",
      "Epoch 23/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6439 - loss: 2.6184\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000245840631A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8/8 - 0s - 41ms/step\n",
      "Epoch 1/23\n",
      "29/29 - 4s - 136ms/step - accuracy: 0.6227 - loss: 2.7093\n",
      "Epoch 2/23\n",
      "29/29 - 1s - 28ms/step - accuracy: 0.6440 - loss: 2.6959\n",
      "Epoch 3/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6909\n",
      "Epoch 4/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6867\n",
      "Epoch 5/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6831\n",
      "Epoch 6/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6797\n",
      "Epoch 7/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6766\n",
      "Epoch 8/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6440 - loss: 2.6737\n",
      "Epoch 9/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6708\n",
      "Epoch 10/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6680\n",
      "Epoch 11/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6653\n",
      "Epoch 12/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6625\n",
      "Epoch 13/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6596\n",
      "Epoch 14/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6566\n",
      "Epoch 15/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6533\n",
      "Epoch 16/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6499\n",
      "Epoch 17/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6460\n",
      "Epoch 18/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6418\n",
      "Epoch 19/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6370\n",
      "Epoch 20/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6315\n",
      "Epoch 21/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6254\n",
      "Epoch 22/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6440 - loss: 2.6184\n",
      "Epoch 23/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6440 - loss: 2.6104\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000245FBCDB9C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8/8 - 0s - 38ms/step\n",
      "Epoch 1/23\n",
      "29/29 - 4s - 133ms/step - accuracy: 0.6311 - loss: 2.7023\n",
      "Epoch 2/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6959\n",
      "Epoch 3/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6909\n",
      "Epoch 4/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6868\n",
      "Epoch 5/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6831\n",
      "Epoch 6/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6798\n",
      "Epoch 7/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6767\n",
      "Epoch 8/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6738\n",
      "Epoch 9/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6710\n",
      "Epoch 10/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6439 - loss: 2.6683\n",
      "Epoch 11/23\n",
      "29/29 - 1s - 32ms/step - accuracy: 0.6439 - loss: 2.6656\n",
      "Epoch 12/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6630\n",
      "Epoch 13/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6603\n",
      "Epoch 14/23\n",
      "29/29 - 1s - 28ms/step - accuracy: 0.6439 - loss: 2.6575\n",
      "Epoch 15/23\n",
      "29/29 - 1s - 27ms/step - accuracy: 0.6439 - loss: 2.6546\n",
      "Epoch 16/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6515\n",
      "Epoch 17/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6482\n",
      "Epoch 18/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6445\n",
      "Epoch 19/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6405\n",
      "Epoch 20/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6361\n",
      "Epoch 21/23\n",
      "29/29 - 1s - 25ms/step - accuracy: 0.6439 - loss: 2.6311\n",
      "Epoch 22/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6254\n",
      "Epoch 23/23\n",
      "29/29 - 1s - 26ms/step - accuracy: 0.6439 - loss: 2.6191\n",
      "8/8 - 0s - 35ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.644    \u001b[0m | \u001b[0m3.371    \u001b[0m | \u001b[0m480.3    \u001b[0m | \u001b[0m0.732    \u001b[0m | \u001b[0m0.1796   \u001b[0m | \u001b[0m23.12    \u001b[0m | \u001b[0m1.312    \u001b[0m | \u001b[0m1.116    \u001b[0m | \u001b[0m2.732    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m73.73    \u001b[0m | \u001b[0m0.02058  \u001b[0m | \u001b[0m6.789    \u001b[0m |\n",
      "Epoch 1/26\n",
      "75/75 - 3s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "19/19 - 0s - 15ms/step\n",
      "Epoch 1/26\n",
      "75/75 - 3s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/26\n",
      "75/75 - 0s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/26\n",
      "75/75 - 1s - 7ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/26\n",
      "75/75 - 0s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/26\n",
      "75/75 - 0s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "19/19 - 0s - 15ms/step\n",
      "Epoch 1/26\n",
      "75/75 - 3s - 34ms/step - accuracy: 0.6362 - loss: nan\n",
      "Epoch 2/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 26/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "19/19 - 0s - 16ms/step\n",
      "Epoch 1/26\n",
      "75/75 - 3s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "19/19 - 0s - 13ms/step\n",
      "Epoch 1/26\n",
      "75/75 - 3s - 41ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/26\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 26/26\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "19/19 - 0s - 15ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.644    \u001b[0m | \u001b[0m7.492    \u001b[0m | \u001b[0m184.9    \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m0.05502  \u001b[0m | \u001b[0m26.08    \u001b[0m | \u001b[0m2.05     \u001b[0m | \u001b[0m1.864    \u001b[0m | \u001b[0m1.582    \u001b[0m | \u001b[0m0.6157   \u001b[0m | \u001b[0m22.55    \u001b[0m | \u001b[0m0.2921   \u001b[0m | \u001b[0m2.565    \u001b[0m |\n",
      "Epoch 1/32\n",
      "34/34 - 4s - 126ms/step - accuracy: 0.6461 - loss: 1.1619\n",
      "Epoch 2/32\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7303 - loss: 0.7941\n",
      "Epoch 3/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7661 - loss: 0.6993\n",
      "Epoch 4/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7822 - loss: 0.6351\n",
      "Epoch 5/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7974 - loss: 0.5789\n",
      "Epoch 6/32\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8124 - loss: 0.5276\n",
      "Epoch 7/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8290 - loss: 0.4783\n",
      "Epoch 8/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8428 - loss: 0.4385\n",
      "Epoch 9/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8571 - loss: 0.4017\n",
      "Epoch 10/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8698 - loss: 0.3708\n",
      "Epoch 11/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8803 - loss: 0.3493\n",
      "Epoch 12/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8831 - loss: 0.3420\n",
      "Epoch 13/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8914 - loss: 0.3198\n",
      "Epoch 14/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8978 - loss: 0.3029\n",
      "Epoch 15/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8998 - loss: 0.2948\n",
      "Epoch 16/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9049 - loss: 0.2820\n",
      "Epoch 17/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9051 - loss: 0.2753\n",
      "Epoch 18/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9131 - loss: 0.2614\n",
      "Epoch 19/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9150 - loss: 0.2517\n",
      "Epoch 20/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9070 - loss: 0.2732\n",
      "Epoch 21/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9205 - loss: 0.2341\n",
      "Epoch 22/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9136 - loss: 0.2497\n",
      "Epoch 23/32\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9211 - loss: 0.2342\n",
      "Epoch 24/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9245 - loss: 0.2192\n",
      "Epoch 25/32\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9279 - loss: 0.2134\n",
      "Epoch 26/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9217 - loss: 0.2256\n",
      "Epoch 27/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9219 - loss: 0.2249\n",
      "Epoch 28/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9294 - loss: 0.2012\n",
      "Epoch 29/32\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.9309 - loss: 0.2013\n",
      "Epoch 30/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9327 - loss: 0.1938\n",
      "Epoch 31/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9375 - loss: 0.1850\n",
      "Epoch 32/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9391 - loss: 0.1837\n",
      "9/9 - 0s - 42ms/step\n",
      "Epoch 1/32\n",
      "34/34 - 5s - 146ms/step - accuracy: 0.6505 - loss: 1.1653\n",
      "Epoch 2/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7301 - loss: 0.7985\n",
      "Epoch 3/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7625 - loss: 0.7040\n",
      "Epoch 4/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7797 - loss: 0.6435\n",
      "Epoch 5/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.7931 - loss: 0.5951\n",
      "Epoch 6/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8088 - loss: 0.5476\n",
      "Epoch 7/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8280 - loss: 0.4976\n",
      "Epoch 8/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8431 - loss: 0.4505\n",
      "Epoch 9/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8584 - loss: 0.4109\n",
      "Epoch 10/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8655 - loss: 0.3840\n",
      "Epoch 11/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8765 - loss: 0.3571\n",
      "Epoch 12/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8786 - loss: 0.3460\n",
      "Epoch 13/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8856 - loss: 0.3318\n",
      "Epoch 14/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8884 - loss: 0.3224\n",
      "Epoch 15/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8982 - loss: 0.2963\n",
      "Epoch 16/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9033 - loss: 0.2862\n",
      "Epoch 17/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9059 - loss: 0.2767\n",
      "Epoch 18/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9048 - loss: 0.2793\n",
      "Epoch 19/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9123 - loss: 0.2620\n",
      "Epoch 20/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9144 - loss: 0.2490\n",
      "Epoch 21/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9166 - loss: 0.2487\n",
      "Epoch 22/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9213 - loss: 0.2333\n",
      "Epoch 23/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9196 - loss: 0.2361\n",
      "Epoch 24/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9225 - loss: 0.2289\n",
      "Epoch 25/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9302 - loss: 0.2107\n",
      "Epoch 26/32\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.9244 - loss: 0.2223\n",
      "Epoch 27/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9264 - loss: 0.2113\n",
      "Epoch 28/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.9287 - loss: 0.2113\n",
      "Epoch 29/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.9341 - loss: 0.1997\n",
      "Epoch 30/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9367 - loss: 0.1887\n",
      "Epoch 31/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9420 - loss: 0.1786\n",
      "Epoch 32/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9346 - loss: 0.1921\n",
      "9/9 - 0s - 40ms/step\n",
      "Epoch 1/32\n",
      "34/34 - 4s - 132ms/step - accuracy: 0.6381 - loss: 1.1569\n",
      "Epoch 2/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7359 - loss: 0.7885\n",
      "Epoch 3/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7700 - loss: 0.6845\n",
      "Epoch 4/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7890 - loss: 0.6196\n",
      "Epoch 5/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8022 - loss: 0.5636\n",
      "Epoch 6/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.8223 - loss: 0.5102\n",
      "Epoch 7/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.8375 - loss: 0.4669\n",
      "Epoch 8/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.8508 - loss: 0.4311\n",
      "Epoch 9/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8633 - loss: 0.3995\n",
      "Epoch 10/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8672 - loss: 0.3826\n",
      "Epoch 11/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8727 - loss: 0.3607\n",
      "Epoch 12/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8818 - loss: 0.3394\n",
      "Epoch 13/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8876 - loss: 0.3259\n",
      "Epoch 14/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8888 - loss: 0.3193\n",
      "Epoch 15/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8931 - loss: 0.3065\n",
      "Epoch 16/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8972 - loss: 0.2896\n",
      "Epoch 17/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8983 - loss: 0.2894\n",
      "Epoch 18/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9009 - loss: 0.2794\n",
      "Epoch 19/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9069 - loss: 0.2657\n",
      "Epoch 20/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9091 - loss: 0.2607\n",
      "Epoch 21/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9118 - loss: 0.2523\n",
      "Epoch 22/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9137 - loss: 0.2432\n",
      "Epoch 23/32\n",
      "34/34 - 1s - 33ms/step - accuracy: 0.9159 - loss: 0.2416\n",
      "Epoch 24/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9212 - loss: 0.2333\n",
      "Epoch 25/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9201 - loss: 0.2248\n",
      "Epoch 26/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9203 - loss: 0.2312\n",
      "Epoch 27/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9209 - loss: 0.2263\n",
      "Epoch 28/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9243 - loss: 0.2170\n",
      "Epoch 29/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9254 - loss: 0.2156\n",
      "Epoch 30/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9304 - loss: 0.1981\n",
      "Epoch 31/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9332 - loss: 0.1939\n",
      "Epoch 32/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9361 - loss: 0.1877\n",
      "9/9 - 0s - 37ms/step\n",
      "Epoch 1/32\n",
      "34/34 - 5s - 136ms/step - accuracy: 0.6377 - loss: 1.1436\n",
      "Epoch 2/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7284 - loss: 0.7936\n",
      "Epoch 3/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7655 - loss: 0.6996\n",
      "Epoch 4/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7850 - loss: 0.6407\n",
      "Epoch 5/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7954 - loss: 0.5949\n",
      "Epoch 6/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8094 - loss: 0.5502\n",
      "Epoch 7/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8208 - loss: 0.5061\n",
      "Epoch 8/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8330 - loss: 0.4668\n",
      "Epoch 9/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8464 - loss: 0.4350\n",
      "Epoch 10/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8566 - loss: 0.4074\n",
      "Epoch 11/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8667 - loss: 0.3834\n",
      "Epoch 12/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8715 - loss: 0.3663\n",
      "Epoch 13/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8824 - loss: 0.3467\n",
      "Epoch 14/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8908 - loss: 0.3234\n",
      "Epoch 15/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8939 - loss: 0.3141\n",
      "Epoch 16/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8937 - loss: 0.3156\n",
      "Epoch 17/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8985 - loss: 0.2983\n",
      "Epoch 18/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9046 - loss: 0.2828\n",
      "Epoch 19/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9023 - loss: 0.2855\n",
      "Epoch 20/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9064 - loss: 0.2726\n",
      "Epoch 21/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9070 - loss: 0.2685\n",
      "Epoch 22/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9090 - loss: 0.2642\n",
      "Epoch 23/32\n",
      "34/34 - 1s - 33ms/step - accuracy: 0.9137 - loss: 0.2519\n",
      "Epoch 24/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9146 - loss: 0.2517\n",
      "Epoch 25/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9174 - loss: 0.2455\n",
      "Epoch 26/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9206 - loss: 0.2329\n",
      "Epoch 27/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9207 - loss: 0.2286\n",
      "Epoch 28/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9218 - loss: 0.2250\n",
      "Epoch 29/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9244 - loss: 0.2133\n",
      "Epoch 30/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9279 - loss: 0.2109\n",
      "Epoch 31/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9273 - loss: 0.2096\n",
      "Epoch 32/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9296 - loss: 0.2082\n",
      "9/9 - 0s - 40ms/step\n",
      "Epoch 1/32\n",
      "34/34 - 5s - 141ms/step - accuracy: 0.6325 - loss: 1.1797\n",
      "Epoch 2/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7340 - loss: 0.7972\n",
      "Epoch 3/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7633 - loss: 0.7104\n",
      "Epoch 4/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7761 - loss: 0.6521\n",
      "Epoch 5/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7926 - loss: 0.6038\n",
      "Epoch 6/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8070 - loss: 0.5583\n",
      "Epoch 7/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8200 - loss: 0.5147\n",
      "Epoch 8/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8351 - loss: 0.4727\n",
      "Epoch 9/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8451 - loss: 0.4362\n",
      "Epoch 10/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.8584 - loss: 0.4048\n",
      "Epoch 11/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8643 - loss: 0.3834\n",
      "Epoch 12/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8743 - loss: 0.3624\n",
      "Epoch 13/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8763 - loss: 0.3490\n",
      "Epoch 14/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8836 - loss: 0.3314\n",
      "Epoch 15/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8848 - loss: 0.3256\n",
      "Epoch 16/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8896 - loss: 0.3122\n",
      "Epoch 17/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8961 - loss: 0.2922\n",
      "Epoch 18/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.8948 - loss: 0.2959\n",
      "Epoch 19/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9025 - loss: 0.2829\n",
      "Epoch 20/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9088 - loss: 0.2657\n",
      "Epoch 21/32\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.9062 - loss: 0.2633\n",
      "Epoch 22/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9155 - loss: 0.2495\n",
      "Epoch 23/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9146 - loss: 0.2422\n",
      "Epoch 24/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.9203 - loss: 0.2356\n",
      "Epoch 25/32\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.9173 - loss: 0.2398\n",
      "Epoch 26/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9160 - loss: 0.2371\n",
      "Epoch 27/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9266 - loss: 0.2177\n",
      "Epoch 28/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9243 - loss: 0.2187\n",
      "Epoch 29/32\n",
      "34/34 - 1s - 29ms/step - accuracy: 0.9276 - loss: 0.2132\n",
      "Epoch 30/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9287 - loss: 0.2084\n",
      "Epoch 31/32\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.9336 - loss: 0.1957\n",
      "Epoch 32/32\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.9355 - loss: 0.1902\n",
      "9/9 - 0s - 37ms/step\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.8405   \u001b[0m | \u001b[95m4.105    \u001b[0m | \u001b[95m414.1    \u001b[0m | \u001b[95m0.1997   \u001b[0m | \u001b[95m0.1543   \u001b[0m | \u001b[95m31.85    \u001b[0m | \u001b[95m1.093    \u001b[0m | \u001b[95m2.215    \u001b[0m | \u001b[95m1.341    \u001b[0m | \u001b[95m0.0744   \u001b[0m | \u001b[95m95.4     \u001b[0m | \u001b[95m0.9656   \u001b[0m | \u001b[95m5.659    \u001b[0m |\n",
      "Epoch 1/22\n",
      "100/100 - 2s - 24ms/step - accuracy: 0.5332 - loss: 2.2592\n",
      "Epoch 2/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6430 - loss: 1.5683\n",
      "Epoch 3/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.3276\n",
      "Epoch 4/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.2379\n",
      "Epoch 5/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1888\n",
      "Epoch 6/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1571\n",
      "Epoch 7/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1347\n",
      "Epoch 8/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.1185\n",
      "Epoch 9/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1044\n",
      "Epoch 10/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6443 - loss: 1.0941\n",
      "Epoch 11/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.0847\n",
      "Epoch 12/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6449 - loss: 1.0768\n",
      "Epoch 13/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6459 - loss: 1.0695\n",
      "Epoch 14/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6471 - loss: 1.0633\n",
      "Epoch 15/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6467 - loss: 1.0580\n",
      "Epoch 16/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6501 - loss: 1.0530\n",
      "Epoch 17/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6502 - loss: 1.0491\n",
      "Epoch 18/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6511 - loss: 1.0445\n",
      "Epoch 19/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6522 - loss: 1.0404\n",
      "Epoch 20/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6504 - loss: 1.0379\n",
      "Epoch 21/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6533 - loss: 1.0332\n",
      "Epoch 22/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6532 - loss: 1.0293\n",
      "25/25 - 0s - 15ms/step\n",
      "Epoch 1/22\n",
      "100/100 - 3s - 32ms/step - accuracy: 0.5648 - loss: 2.0678\n",
      "Epoch 2/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6429 - loss: 1.4421\n",
      "Epoch 3/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6438 - loss: 1.2731\n",
      "Epoch 4/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.2040\n",
      "Epoch 5/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1649\n",
      "Epoch 6/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.1397\n",
      "Epoch 7/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1203\n",
      "Epoch 8/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.1059\n",
      "Epoch 9/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6438 - loss: 1.0946\n",
      "Epoch 10/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6449 - loss: 1.0844\n",
      "Epoch 11/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6451 - loss: 1.0778\n",
      "Epoch 12/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6463 - loss: 1.0716\n",
      "Epoch 13/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6467 - loss: 1.0651\n",
      "Epoch 14/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6490 - loss: 1.0608\n",
      "Epoch 15/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6496 - loss: 1.0558\n",
      "Epoch 16/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6514 - loss: 1.0521\n",
      "Epoch 17/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6499 - loss: 1.0489\n",
      "Epoch 18/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6536 - loss: 1.0450\n",
      "Epoch 19/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6536 - loss: 1.0424\n",
      "Epoch 20/22\n",
      "100/100 - 1s - 13ms/step - accuracy: 0.6539 - loss: 1.0392\n",
      "Epoch 21/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6565 - loss: 1.0364\n",
      "Epoch 22/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6579 - loss: 1.0335\n",
      "25/25 - 0s - 13ms/step\n",
      "Epoch 1/22\n",
      "100/100 - 2s - 25ms/step - accuracy: 0.5973 - loss: 2.0352\n",
      "Epoch 2/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6418 - loss: 1.4722\n",
      "Epoch 3/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6437 - loss: 1.2938\n",
      "Epoch 4/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.2182\n",
      "Epoch 5/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1754\n",
      "Epoch 6/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1479\n",
      "Epoch 7/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1274\n",
      "Epoch 8/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.1125\n",
      "Epoch 9/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1003\n",
      "Epoch 10/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0902\n",
      "Epoch 11/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6441 - loss: 1.0816\n",
      "Epoch 12/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6447 - loss: 1.0745\n",
      "Epoch 13/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6447 - loss: 1.0677\n",
      "Epoch 14/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6458 - loss: 1.0617\n",
      "Epoch 15/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6482 - loss: 1.0566\n",
      "Epoch 16/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6506 - loss: 1.0521\n",
      "Epoch 17/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6507 - loss: 1.0478\n",
      "Epoch 18/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6544 - loss: 1.0426\n",
      "Epoch 19/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6539 - loss: 1.0398\n",
      "Epoch 20/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6590 - loss: 1.0351\n",
      "Epoch 21/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6615 - loss: 1.0312\n",
      "Epoch 22/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6598 - loss: 1.0281\n",
      "25/25 - 0s - 13ms/step\n",
      "Epoch 1/22\n",
      "100/100 - 2s - 24ms/step - accuracy: 0.6023 - loss: 2.0201\n",
      "Epoch 2/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6438 - loss: 1.4363\n",
      "Epoch 3/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.2685\n",
      "Epoch 4/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.2022\n",
      "Epoch 5/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1651\n",
      "Epoch 6/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1408\n",
      "Epoch 7/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6441 - loss: 1.1215\n",
      "Epoch 8/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6446 - loss: 1.1069\n",
      "Epoch 9/22\n",
      "100/100 - 1s - 10ms/step - accuracy: 0.6450 - loss: 1.0958\n",
      "Epoch 10/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6467 - loss: 1.0857\n",
      "Epoch 11/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6480 - loss: 1.0771\n",
      "Epoch 12/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6501 - loss: 1.0692\n",
      "Epoch 13/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6505 - loss: 1.0633\n",
      "Epoch 14/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6549 - loss: 1.0564\n",
      "Epoch 15/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6545 - loss: 1.0500\n",
      "Epoch 16/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6566 - loss: 1.0454\n",
      "Epoch 17/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6598 - loss: 1.0402\n",
      "Epoch 18/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6606 - loss: 1.0355\n",
      "Epoch 19/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6622 - loss: 1.0300\n",
      "Epoch 20/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6643 - loss: 1.0255\n",
      "Epoch 21/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6661 - loss: 1.0204\n",
      "Epoch 22/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6660 - loss: 1.0163\n",
      "25/25 - 0s - 13ms/step\n",
      "Epoch 1/22\n",
      "100/100 - 2s - 24ms/step - accuracy: 0.5813 - loss: 2.0855\n",
      "Epoch 2/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6399 - loss: 1.4898\n",
      "Epoch 3/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6426 - loss: 1.2970\n",
      "Epoch 4/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6436 - loss: 1.2198\n",
      "Epoch 5/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6437 - loss: 1.1786\n",
      "Epoch 6/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.1512\n",
      "Epoch 7/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1323\n",
      "Epoch 8/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.1179\n",
      "Epoch 9/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.1062\n",
      "Epoch 10/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0971\n",
      "Epoch 11/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0895\n",
      "Epoch 12/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.0827\n",
      "Epoch 13/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0756\n",
      "Epoch 14/22\n",
      "100/100 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.0713\n",
      "Epoch 15/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.0662\n",
      "Epoch 16/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0615\n",
      "Epoch 17/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6442 - loss: 1.0585\n",
      "Epoch 18/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6444 - loss: 1.0546\n",
      "Epoch 19/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6450 - loss: 1.0506\n",
      "Epoch 20/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6447 - loss: 1.0481\n",
      "Epoch 21/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6457 - loss: 1.0452\n",
      "Epoch 22/22\n",
      "100/100 - 1s - 8ms/step - accuracy: 0.6460 - loss: 1.0419\n",
      "25/25 - 0s - 13ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6594   \u001b[0m | \u001b[0m2.742    \u001b[0m | \u001b[0m139.1    \u001b[0m | \u001b[0m0.6842   \u001b[0m | \u001b[0m0.132    \u001b[0m | \u001b[0m22.44    \u001b[0m | \u001b[0m1.99     \u001b[0m | \u001b[0m1.069    \u001b[0m | \u001b[0m2.819    \u001b[0m | \u001b[0m0.2662   \u001b[0m | \u001b[0m69.63    \u001b[0m | \u001b[0m0.3117   \u001b[0m | \u001b[0m3.64     \u001b[0m |\n",
      "Epoch 1/39\n",
      "80/80 - 3s - 33ms/step - accuracy: 0.6244 - loss: 1.1490\n",
      "Epoch 2/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.6964 - loss: 0.8817\n",
      "Epoch 3/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7282 - loss: 0.7960\n",
      "Epoch 4/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.7457 - loss: 0.7452\n",
      "Epoch 5/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.7534 - loss: 0.7096\n",
      "Epoch 6/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.7603 - loss: 0.6789\n",
      "Epoch 7/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7701 - loss: 0.6620\n",
      "Epoch 8/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.7729 - loss: 0.6404\n",
      "Epoch 9/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7802 - loss: 0.6250\n",
      "Epoch 10/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7852 - loss: 0.6127\n",
      "Epoch 11/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7895 - loss: 0.5949\n",
      "Epoch 12/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7900 - loss: 0.5886\n",
      "Epoch 13/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7954 - loss: 0.5735\n",
      "Epoch 14/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7950 - loss: 0.5666\n",
      "Epoch 15/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8005 - loss: 0.5556\n",
      "Epoch 16/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8035 - loss: 0.5479\n",
      "Epoch 17/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8075 - loss: 0.5374\n",
      "Epoch 18/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8087 - loss: 0.5283\n",
      "Epoch 19/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8142 - loss: 0.5153\n",
      "Epoch 20/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8163 - loss: 0.5111\n",
      "Epoch 21/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8216 - loss: 0.4980\n",
      "Epoch 22/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8179 - loss: 0.4987\n",
      "Epoch 23/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8230 - loss: 0.4867\n",
      "Epoch 24/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8284 - loss: 0.4811\n",
      "Epoch 25/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8330 - loss: 0.4693\n",
      "Epoch 26/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8267 - loss: 0.4754\n",
      "Epoch 27/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8359 - loss: 0.4605\n",
      "Epoch 28/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8372 - loss: 0.4552\n",
      "Epoch 29/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8380 - loss: 0.4446\n",
      "Epoch 30/39\n",
      "80/80 - 0s - 5ms/step - accuracy: 0.8384 - loss: 0.4469\n",
      "Epoch 31/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8462 - loss: 0.4308\n",
      "Epoch 32/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8406 - loss: 0.4308\n",
      "Epoch 33/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8486 - loss: 0.4211\n",
      "Epoch 34/39\n",
      "80/80 - 0s - 5ms/step - accuracy: 0.8493 - loss: 0.4196\n",
      "Epoch 35/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8524 - loss: 0.4106\n",
      "Epoch 36/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8550 - loss: 0.4014\n",
      "Epoch 37/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8542 - loss: 0.4014\n",
      "Epoch 38/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8574 - loss: 0.3938\n",
      "Epoch 39/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8618 - loss: 0.3861\n",
      "20/20 - 0s - 19ms/step\n",
      "Epoch 1/39\n",
      "80/80 - 3s - 37ms/step - accuracy: 0.6354 - loss: 1.1712\n",
      "Epoch 2/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.6982 - loss: 0.8819\n",
      "Epoch 3/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7272 - loss: 0.7889\n",
      "Epoch 4/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7501 - loss: 0.7289\n",
      "Epoch 5/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7593 - loss: 0.6908\n",
      "Epoch 6/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7690 - loss: 0.6578\n",
      "Epoch 7/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7718 - loss: 0.6398\n",
      "Epoch 8/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7852 - loss: 0.6118\n",
      "Epoch 9/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7874 - loss: 0.5958\n",
      "Epoch 10/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7929 - loss: 0.5790\n",
      "Epoch 11/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7975 - loss: 0.5663\n",
      "Epoch 12/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8026 - loss: 0.5486\n",
      "Epoch 13/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8055 - loss: 0.5353\n",
      "Epoch 14/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8102 - loss: 0.5292\n",
      "Epoch 15/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8139 - loss: 0.5115\n",
      "Epoch 16/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8167 - loss: 0.4992\n",
      "Epoch 17/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8221 - loss: 0.4848\n",
      "Epoch 18/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8271 - loss: 0.4736\n",
      "Epoch 19/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8321 - loss: 0.4641\n",
      "Epoch 20/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8327 - loss: 0.4600\n",
      "Epoch 21/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8362 - loss: 0.4456\n",
      "Epoch 22/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8387 - loss: 0.4424\n",
      "Epoch 23/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8474 - loss: 0.4289\n",
      "Epoch 24/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8469 - loss: 0.4217\n",
      "Epoch 25/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8521 - loss: 0.4102\n",
      "Epoch 26/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8524 - loss: 0.4030\n",
      "Epoch 27/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8545 - loss: 0.4032\n",
      "Epoch 28/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8567 - loss: 0.3890\n",
      "Epoch 29/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8617 - loss: 0.3827\n",
      "Epoch 30/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8646 - loss: 0.3734\n",
      "Epoch 31/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8661 - loss: 0.3737\n",
      "Epoch 32/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8665 - loss: 0.3702\n",
      "Epoch 33/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8752 - loss: 0.3528\n",
      "Epoch 34/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8773 - loss: 0.3551\n",
      "Epoch 35/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8725 - loss: 0.3512\n",
      "Epoch 36/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8781 - loss: 0.3435\n",
      "Epoch 37/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8776 - loss: 0.3411\n",
      "Epoch 38/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8832 - loss: 0.3324\n",
      "Epoch 39/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8824 - loss: 0.3299\n",
      "20/20 - 0s - 16ms/step\n",
      "Epoch 1/39\n",
      "80/80 - 2s - 30ms/step - accuracy: 0.6152 - loss: 1.2508\n",
      "Epoch 2/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.6818 - loss: 0.9240\n",
      "Epoch 3/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7142 - loss: 0.8354\n",
      "Epoch 4/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7285 - loss: 0.7746\n",
      "Epoch 5/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7503 - loss: 0.7205\n",
      "Epoch 6/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7593 - loss: 0.6874\n",
      "Epoch 7/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7683 - loss: 0.6601\n",
      "Epoch 8/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7718 - loss: 0.6339\n",
      "Epoch 9/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7804 - loss: 0.6124\n",
      "Epoch 10/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7858 - loss: 0.5974\n",
      "Epoch 11/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7914 - loss: 0.5841\n",
      "Epoch 12/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7975 - loss: 0.5644\n",
      "Epoch 13/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8046 - loss: 0.5497\n",
      "Epoch 14/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8060 - loss: 0.5412\n",
      "Epoch 15/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8107 - loss: 0.5274\n",
      "Epoch 16/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8143 - loss: 0.5185\n",
      "Epoch 17/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8207 - loss: 0.5045\n",
      "Epoch 18/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8219 - loss: 0.4957\n",
      "Epoch 19/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8264 - loss: 0.4827\n",
      "Epoch 20/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8262 - loss: 0.4847\n",
      "Epoch 21/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8331 - loss: 0.4721\n",
      "Epoch 22/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8330 - loss: 0.4625\n",
      "Epoch 23/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8364 - loss: 0.4526\n",
      "Epoch 24/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8404 - loss: 0.4425\n",
      "Epoch 25/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8406 - loss: 0.4405\n",
      "Epoch 26/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8450 - loss: 0.4333\n",
      "Epoch 27/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8515 - loss: 0.4253\n",
      "Epoch 28/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8515 - loss: 0.4222\n",
      "Epoch 29/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8534 - loss: 0.4139\n",
      "Epoch 30/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8582 - loss: 0.4055\n",
      "Epoch 31/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8555 - loss: 0.4035\n",
      "Epoch 32/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8611 - loss: 0.3944\n",
      "Epoch 33/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8594 - loss: 0.3937\n",
      "Epoch 34/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8603 - loss: 0.3915\n",
      "Epoch 35/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8625 - loss: 0.3812\n",
      "Epoch 36/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8646 - loss: 0.3810\n",
      "Epoch 37/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8660 - loss: 0.3784\n",
      "Epoch 38/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8702 - loss: 0.3666\n",
      "Epoch 39/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8707 - loss: 0.3617\n",
      "20/20 - 0s - 16ms/step\n",
      "Epoch 1/39\n",
      "80/80 - 2s - 30ms/step - accuracy: 0.6312 - loss: 1.1717\n",
      "Epoch 2/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.7175 - loss: 0.8364\n",
      "Epoch 3/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7450 - loss: 0.7496\n",
      "Epoch 4/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7548 - loss: 0.7125\n",
      "Epoch 5/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7654 - loss: 0.6818\n",
      "Epoch 6/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7723 - loss: 0.6534\n",
      "Epoch 7/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7752 - loss: 0.6344\n",
      "Epoch 8/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7801 - loss: 0.6191\n",
      "Epoch 9/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.7821 - loss: 0.6043\n",
      "Epoch 10/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7905 - loss: 0.5871\n",
      "Epoch 11/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7976 - loss: 0.5729\n",
      "Epoch 12/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.7992 - loss: 0.5598\n",
      "Epoch 13/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8040 - loss: 0.5459\n",
      "Epoch 14/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8094 - loss: 0.5320\n",
      "Epoch 15/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8126 - loss: 0.5189\n",
      "Epoch 16/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8171 - loss: 0.5084\n",
      "Epoch 17/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8176 - loss: 0.4982\n",
      "Epoch 18/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8186 - loss: 0.4954\n",
      "Epoch 19/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8266 - loss: 0.4814\n",
      "Epoch 20/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8307 - loss: 0.4724\n",
      "Epoch 21/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8340 - loss: 0.4621\n",
      "Epoch 22/39\n",
      "80/80 - 0s - 5ms/step - accuracy: 0.8328 - loss: 0.4566\n",
      "Epoch 23/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8405 - loss: 0.4424\n",
      "Epoch 24/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8415 - loss: 0.4341\n",
      "Epoch 25/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8454 - loss: 0.4328\n",
      "Epoch 26/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8470 - loss: 0.4276\n",
      "Epoch 27/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8467 - loss: 0.4215\n",
      "Epoch 28/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8545 - loss: 0.4064\n",
      "Epoch 29/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8511 - loss: 0.4066\n",
      "Epoch 30/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8565 - loss: 0.3951\n",
      "Epoch 31/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8609 - loss: 0.3851\n",
      "Epoch 32/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8604 - loss: 0.3852\n",
      "Epoch 33/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8666 - loss: 0.3738\n",
      "Epoch 34/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8629 - loss: 0.3763\n",
      "Epoch 35/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8658 - loss: 0.3712\n",
      "Epoch 36/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8662 - loss: 0.3669\n",
      "Epoch 37/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8716 - loss: 0.3573\n",
      "Epoch 38/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8705 - loss: 0.3619\n",
      "Epoch 39/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8749 - loss: 0.3468\n",
      "20/20 - 0s - 17ms/step\n",
      "Epoch 1/39\n",
      "80/80 - 3s - 34ms/step - accuracy: 0.6002 - loss: 1.3914\n",
      "Epoch 2/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.6975 - loss: 0.8996\n",
      "Epoch 3/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7277 - loss: 0.7974\n",
      "Epoch 4/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7405 - loss: 0.7466\n",
      "Epoch 5/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7614 - loss: 0.6993\n",
      "Epoch 6/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.7609 - loss: 0.6778\n",
      "Epoch 7/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7694 - loss: 0.6490\n",
      "Epoch 8/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7749 - loss: 0.6301\n",
      "Epoch 9/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7805 - loss: 0.6126\n",
      "Epoch 10/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.7845 - loss: 0.6020\n",
      "Epoch 11/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.7880 - loss: 0.5889\n",
      "Epoch 12/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.7969 - loss: 0.5719\n",
      "Epoch 13/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8004 - loss: 0.5572\n",
      "Epoch 14/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8028 - loss: 0.5468\n",
      "Epoch 15/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8111 - loss: 0.5279\n",
      "Epoch 16/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8065 - loss: 0.5277\n",
      "Epoch 17/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8112 - loss: 0.5158\n",
      "Epoch 18/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8154 - loss: 0.5090\n",
      "Epoch 19/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8221 - loss: 0.4914\n",
      "Epoch 20/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8256 - loss: 0.4841\n",
      "Epoch 21/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8264 - loss: 0.4770\n",
      "Epoch 22/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8304 - loss: 0.4668\n",
      "Epoch 23/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8309 - loss: 0.4627\n",
      "Epoch 24/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8351 - loss: 0.4556\n",
      "Epoch 25/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8384 - loss: 0.4434\n",
      "Epoch 26/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8424 - loss: 0.4345\n",
      "Epoch 27/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8463 - loss: 0.4271\n",
      "Epoch 28/39\n",
      "80/80 - 1s - 8ms/step - accuracy: 0.8481 - loss: 0.4204\n",
      "Epoch 29/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8487 - loss: 0.4174\n",
      "Epoch 30/39\n",
      "80/80 - 0s - 5ms/step - accuracy: 0.8503 - loss: 0.4113\n",
      "Epoch 31/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8510 - loss: 0.4065\n",
      "Epoch 32/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8548 - loss: 0.4000\n",
      "Epoch 33/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8624 - loss: 0.3936\n",
      "Epoch 34/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8612 - loss: 0.3867\n",
      "Epoch 35/39\n",
      "80/80 - 1s - 7ms/step - accuracy: 0.8615 - loss: 0.3838\n",
      "Epoch 36/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8617 - loss: 0.3783\n",
      "Epoch 37/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8678 - loss: 0.3686\n",
      "Epoch 38/39\n",
      "80/80 - 0s - 6ms/step - accuracy: 0.8665 - loss: 0.3736\n",
      "Epoch 39/39\n",
      "80/80 - 1s - 6ms/step - accuracy: 0.8707 - loss: 0.3600\n",
      "20/20 - 0s - 17ms/step\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.8409   \u001b[0m | \u001b[95m4.92     \u001b[0m | \u001b[95m173.9    \u001b[0m | \u001b[95m0.9696   \u001b[0m | \u001b[95m0.2325   \u001b[0m | \u001b[95m38.79    \u001b[0m | \u001b[95m2.79     \u001b[0m | \u001b[95m2.196    \u001b[0m | \u001b[95m2.844    \u001b[0m | \u001b[95m0.09761  \u001b[0m | \u001b[95m27.64    \u001b[0m | \u001b[95m0.04523  \u001b[0m | \u001b[95m2.277    \u001b[0m |\n",
      "Epoch 1/26\n",
      "66/66 - 5s - 73ms/step - accuracy: 0.6674 - loss: 1.0747\n",
      "Epoch 2/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.7505 - loss: 0.7266\n",
      "Epoch 3/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.7804 - loss: 0.6368\n",
      "Epoch 4/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8006 - loss: 0.5787\n",
      "Epoch 5/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8141 - loss: 0.5406\n",
      "Epoch 6/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8284 - loss: 0.4985\n",
      "Epoch 7/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8320 - loss: 0.4794\n",
      "Epoch 8/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8486 - loss: 0.4376\n",
      "Epoch 9/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8519 - loss: 0.4195\n",
      "Epoch 10/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8612 - loss: 0.3927\n",
      "Epoch 11/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8646 - loss: 0.3806\n",
      "Epoch 12/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8631 - loss: 0.3821\n",
      "Epoch 13/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8719 - loss: 0.3608\n",
      "Epoch 14/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8782 - loss: 0.3429\n",
      "Epoch 15/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8858 - loss: 0.3246\n",
      "Epoch 16/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8895 - loss: 0.3130\n",
      "Epoch 17/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8895 - loss: 0.3105\n",
      "Epoch 18/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8978 - loss: 0.2930\n",
      "Epoch 19/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.8963 - loss: 0.2933\n",
      "Epoch 20/26\n",
      "66/66 - 1s - 20ms/step - accuracy: 0.9004 - loss: 0.2801\n",
      "Epoch 21/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9009 - loss: 0.2825\n",
      "Epoch 22/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9105 - loss: 0.2573\n",
      "Epoch 23/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9118 - loss: 0.2553\n",
      "Epoch 24/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9103 - loss: 0.2580\n",
      "Epoch 25/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9179 - loss: 0.2410\n",
      "Epoch 26/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9188 - loss: 0.2383\n",
      "17/17 - 0s - 24ms/step\n",
      "Epoch 1/26\n",
      "66/66 - 5s - 76ms/step - accuracy: 0.6740 - loss: 1.0576\n",
      "Epoch 2/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.7618 - loss: 0.7106\n",
      "Epoch 3/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.7898 - loss: 0.6197\n",
      "Epoch 4/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8037 - loss: 0.5614\n",
      "Epoch 5/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8211 - loss: 0.4999\n",
      "Epoch 6/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8372 - loss: 0.4626\n",
      "Epoch 7/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8490 - loss: 0.4300\n",
      "Epoch 8/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8537 - loss: 0.4118\n",
      "Epoch 9/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8643 - loss: 0.3900\n",
      "Epoch 10/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8685 - loss: 0.3701\n",
      "Epoch 11/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8762 - loss: 0.3507\n",
      "Epoch 12/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8797 - loss: 0.3446\n",
      "Epoch 13/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8847 - loss: 0.3280\n",
      "Epoch 14/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8931 - loss: 0.3085\n",
      "Epoch 15/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8917 - loss: 0.3080\n",
      "Epoch 16/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8954 - loss: 0.3002\n",
      "Epoch 17/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8994 - loss: 0.2824\n",
      "Epoch 18/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.8985 - loss: 0.2866\n",
      "Epoch 19/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9029 - loss: 0.2737\n",
      "Epoch 20/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9089 - loss: 0.2602\n",
      "Epoch 21/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9103 - loss: 0.2553\n",
      "Epoch 22/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9131 - loss: 0.2484\n",
      "Epoch 23/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9181 - loss: 0.2400\n",
      "Epoch 24/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9214 - loss: 0.2265\n",
      "Epoch 25/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9250 - loss: 0.2152\n",
      "Epoch 26/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.9205 - loss: 0.2241\n",
      "17/17 - 0s - 22ms/step\n",
      "Epoch 1/26\n",
      "66/66 - 5s - 82ms/step - accuracy: 0.6666 - loss: 1.0680\n",
      "Epoch 2/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.7479 - loss: 0.7405\n",
      "Epoch 3/26\n",
      "66/66 - 1s - 21ms/step - accuracy: 0.7804 - loss: 0.6470\n",
      "Epoch 4/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.7991 - loss: 0.5840\n",
      "Epoch 5/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8136 - loss: 0.5395\n",
      "Epoch 6/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8227 - loss: 0.5061\n",
      "Epoch 7/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8366 - loss: 0.4650\n",
      "Epoch 8/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8483 - loss: 0.4382\n",
      "Epoch 9/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8495 - loss: 0.4234\n",
      "Epoch 10/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8607 - loss: 0.3968\n",
      "Epoch 11/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8688 - loss: 0.3658\n",
      "Epoch 12/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8708 - loss: 0.3655\n",
      "Epoch 13/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8818 - loss: 0.3392\n",
      "Epoch 14/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8785 - loss: 0.3422\n",
      "Epoch 15/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8817 - loss: 0.3261\n",
      "Epoch 16/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8910 - loss: 0.3129\n",
      "Epoch 17/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8931 - loss: 0.3008\n",
      "Epoch 18/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8904 - loss: 0.3133\n",
      "Epoch 19/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8976 - loss: 0.2884\n",
      "Epoch 20/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8975 - loss: 0.2833\n",
      "Epoch 21/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9070 - loss: 0.2649\n",
      "Epoch 22/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9074 - loss: 0.2642\n",
      "Epoch 23/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9139 - loss: 0.2446\n",
      "Epoch 24/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9082 - loss: 0.2608\n",
      "Epoch 25/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9134 - loss: 0.2422\n",
      "Epoch 26/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9171 - loss: 0.2343\n",
      "17/17 - 0s - 23ms/step\n",
      "Epoch 1/26\n",
      "66/66 - 5s - 72ms/step - accuracy: 0.6649 - loss: 1.0726\n",
      "Epoch 2/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.7426 - loss: 0.7595\n",
      "Epoch 3/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.7747 - loss: 0.6629\n",
      "Epoch 4/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.7941 - loss: 0.5976\n",
      "Epoch 5/26\n",
      "66/66 - 2s - 27ms/step - accuracy: 0.8068 - loss: 0.5584\n",
      "Epoch 6/26\n",
      "66/66 - 2s - 25ms/step - accuracy: 0.8221 - loss: 0.5114\n",
      "Epoch 7/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8282 - loss: 0.4901\n",
      "Epoch 8/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8417 - loss: 0.4506\n",
      "Epoch 9/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8480 - loss: 0.4300\n",
      "Epoch 10/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8582 - loss: 0.4037\n",
      "Epoch 11/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8638 - loss: 0.3866\n",
      "Epoch 12/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8698 - loss: 0.3700\n",
      "Epoch 13/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.8728 - loss: 0.3547\n",
      "Epoch 14/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8843 - loss: 0.3288\n",
      "Epoch 15/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8894 - loss: 0.3145\n",
      "Epoch 16/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.8924 - loss: 0.3021\n",
      "Epoch 17/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8991 - loss: 0.2878\n",
      "Epoch 18/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.9001 - loss: 0.2774\n",
      "Epoch 19/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.9033 - loss: 0.2761\n",
      "Epoch 20/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.9067 - loss: 0.2656\n",
      "Epoch 21/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9090 - loss: 0.2546\n",
      "Epoch 22/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9145 - loss: 0.2486\n",
      "Epoch 23/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9194 - loss: 0.2308\n",
      "Epoch 24/26\n",
      "66/66 - 3s - 40ms/step - accuracy: 0.9171 - loss: 0.2349\n",
      "Epoch 25/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.9190 - loss: 0.2303\n",
      "Epoch 26/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.9238 - loss: 0.2216\n",
      "17/17 - 0s - 28ms/step\n",
      "Epoch 1/26\n",
      "66/66 - 6s - 91ms/step - accuracy: 0.6746 - loss: 1.0458\n",
      "Epoch 2/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.7537 - loss: 0.7226\n",
      "Epoch 3/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.7801 - loss: 0.6352\n",
      "Epoch 4/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.7978 - loss: 0.5807\n",
      "Epoch 5/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8095 - loss: 0.5357\n",
      "Epoch 6/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8231 - loss: 0.5017\n",
      "Epoch 7/26\n",
      "66/66 - 2s - 25ms/step - accuracy: 0.8334 - loss: 0.4618\n",
      "Epoch 8/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.8473 - loss: 0.4334\n",
      "Epoch 9/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8558 - loss: 0.4038\n",
      "Epoch 10/26\n",
      "66/66 - 2s - 26ms/step - accuracy: 0.8657 - loss: 0.3821\n",
      "Epoch 11/26\n",
      "66/66 - 1s - 22ms/step - accuracy: 0.8721 - loss: 0.3624\n",
      "Epoch 12/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8766 - loss: 0.3430\n",
      "Epoch 13/26\n",
      "66/66 - 3s - 39ms/step - accuracy: 0.8877 - loss: 0.3250\n",
      "Epoch 14/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8781 - loss: 0.3499\n",
      "Epoch 15/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8870 - loss: 0.3183\n",
      "Epoch 16/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8887 - loss: 0.3107\n",
      "Epoch 17/26\n",
      "66/66 - 2s - 25ms/step - accuracy: 0.8972 - loss: 0.2927\n",
      "Epoch 18/26\n",
      "66/66 - 2s - 24ms/step - accuracy: 0.8991 - loss: 0.2843\n",
      "Epoch 19/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.9018 - loss: 0.2770\n",
      "Epoch 20/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.9045 - loss: 0.2757\n",
      "Epoch 21/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.9098 - loss: 0.2565\n",
      "Epoch 22/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.9094 - loss: 0.2572\n",
      "Epoch 23/26\n",
      "66/66 - 1s - 23ms/step - accuracy: 0.9151 - loss: 0.2397\n",
      "Epoch 24/26\n",
      "66/66 - 2s - 23ms/step - accuracy: 0.9144 - loss: 0.2433\n",
      "Epoch 25/26\n",
      "66/66 - 2s - 25ms/step - accuracy: 0.9121 - loss: 0.2480\n",
      "Epoch 26/26\n",
      "66/66 - 3s - 39ms/step - accuracy: 0.9201 - loss: 0.2252\n",
      "17/17 - 1s - 40ms/step\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.8997   \u001b[0m | \u001b[95m3.498    \u001b[0m | \u001b[95m208.5    \u001b[0m | \u001b[95m0.8287   \u001b[0m | \u001b[95m0.107    \u001b[0m | \u001b[95m25.62    \u001b[0m | \u001b[95m2.085    \u001b[0m | \u001b[95m1.282    \u001b[0m | \u001b[95m2.604    \u001b[0m | \u001b[95m0.08381  \u001b[0m | \u001b[95m98.82    \u001b[0m | \u001b[95m0.7722   \u001b[0m | \u001b[95m1.391    \u001b[0m |\n",
      "Epoch 1/35\n",
      "33/33 - 3s - 78ms/step - accuracy: 0.6178 - loss: 1.2335\n",
      "Epoch 2/35\n",
      "33/33 - 1s - 24ms/step - accuracy: 0.6562 - loss: 1.0678\n",
      "Epoch 3/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.6571 - loss: 1.0301\n",
      "Epoch 4/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.6684 - loss: 0.9984\n",
      "Epoch 5/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.6756 - loss: 0.9740\n",
      "Epoch 6/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.6780 - loss: 0.9586\n",
      "Epoch 7/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.6863 - loss: 0.9362\n",
      "Epoch 8/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.6920 - loss: 0.9213\n",
      "Epoch 9/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.6888 - loss: 0.9199\n",
      "Epoch 10/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.6934 - loss: 0.9064\n",
      "Epoch 11/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.6947 - loss: 0.8899\n",
      "Epoch 12/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7019 - loss: 0.8762\n",
      "Epoch 13/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.6993 - loss: 0.8778\n",
      "Epoch 14/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7039 - loss: 0.8671\n",
      "Epoch 15/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7051 - loss: 0.8616\n",
      "Epoch 16/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7061 - loss: 0.8553\n",
      "Epoch 17/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7082 - loss: 0.8508\n",
      "Epoch 18/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7075 - loss: 0.8443\n",
      "Epoch 19/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7111 - loss: 0.8368\n",
      "Epoch 20/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7156 - loss: 0.8338\n",
      "Epoch 21/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7127 - loss: 0.8291\n",
      "Epoch 22/35\n",
      "33/33 - 1s - 24ms/step - accuracy: 0.7123 - loss: 0.8237\n",
      "Epoch 23/35\n",
      "33/33 - 1s - 23ms/step - accuracy: 0.7192 - loss: 0.8196\n",
      "Epoch 24/35\n",
      "33/33 - 1s - 22ms/step - accuracy: 0.7234 - loss: 0.8098\n",
      "Epoch 25/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7185 - loss: 0.8123\n",
      "Epoch 26/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7192 - loss: 0.8109\n",
      "Epoch 27/35\n",
      "33/33 - 1s - 23ms/step - accuracy: 0.7228 - loss: 0.8038\n",
      "Epoch 28/35\n",
      "33/33 - 1s - 19ms/step - accuracy: 0.7176 - loss: 0.8047\n",
      "Epoch 29/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.7225 - loss: 0.7951\n",
      "Epoch 30/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7231 - loss: 0.7983\n",
      "Epoch 31/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7249 - loss: 0.7903\n",
      "Epoch 32/35\n",
      "33/33 - 1s - 25ms/step - accuracy: 0.7246 - loss: 0.7865\n",
      "Epoch 33/35\n",
      "33/33 - 1s - 22ms/step - accuracy: 0.7271 - loss: 0.7874\n",
      "Epoch 34/35\n",
      "33/33 - 1s - 21ms/step - accuracy: 0.7246 - loss: 0.7889\n",
      "Epoch 35/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.7318 - loss: 0.7785\n",
      "9/9 - 1s - 63ms/step\n",
      "Epoch 1/35\n",
      "33/33 - 3s - 100ms/step - accuracy: 0.6029 - loss: 1.4061\n",
      "Epoch 2/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6500 - loss: 1.0624\n",
      "Epoch 3/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6628 - loss: 1.0096\n",
      "Epoch 4/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.6693 - loss: 0.9831\n",
      "Epoch 5/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6802 - loss: 0.9512\n",
      "Epoch 6/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6827 - loss: 0.9312\n",
      "Epoch 7/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.6932 - loss: 0.9184\n",
      "Epoch 8/35\n",
      "33/33 - 1s - 22ms/step - accuracy: 0.6970 - loss: 0.8948\n",
      "Epoch 9/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6985 - loss: 0.8912\n",
      "Epoch 10/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7078 - loss: 0.8736\n",
      "Epoch 11/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7070 - loss: 0.8670\n",
      "Epoch 12/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7107 - loss: 0.8529\n",
      "Epoch 13/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7101 - loss: 0.8472\n",
      "Epoch 14/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7084 - loss: 0.8419\n",
      "Epoch 15/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7149 - loss: 0.8359\n",
      "Epoch 16/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7132 - loss: 0.8332\n",
      "Epoch 17/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7182 - loss: 0.8243\n",
      "Epoch 18/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7179 - loss: 0.8198\n",
      "Epoch 19/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7197 - loss: 0.8171\n",
      "Epoch 20/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7234 - loss: 0.8075\n",
      "Epoch 21/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7247 - loss: 0.8047\n",
      "Epoch 22/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7221 - loss: 0.8011\n",
      "Epoch 23/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7197 - loss: 0.8032\n",
      "Epoch 24/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7220 - loss: 0.8027\n",
      "Epoch 25/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7291 - loss: 0.7923\n",
      "Epoch 26/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7228 - loss: 0.7886\n",
      "Epoch 27/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7284 - loss: 0.7819\n",
      "Epoch 28/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7336 - loss: 0.7776\n",
      "Epoch 29/35\n",
      "33/33 - 1s - 21ms/step - accuracy: 0.7297 - loss: 0.7768\n",
      "Epoch 30/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7316 - loss: 0.7779\n",
      "Epoch 31/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7326 - loss: 0.7778\n",
      "Epoch 32/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7353 - loss: 0.7691\n",
      "Epoch 33/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7320 - loss: 0.7718\n",
      "Epoch 34/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7324 - loss: 0.7697\n",
      "Epoch 35/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7377 - loss: 0.7649\n",
      "9/9 - 0s - 31ms/step\n",
      "Epoch 1/35\n",
      "33/33 - 2s - 53ms/step - accuracy: 0.6166 - loss: 1.2433\n",
      "Epoch 2/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6561 - loss: 1.0246\n",
      "Epoch 3/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6687 - loss: 0.9815\n",
      "Epoch 4/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6757 - loss: 0.9540\n",
      "Epoch 5/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6834 - loss: 0.9363\n",
      "Epoch 6/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6823 - loss: 0.9294\n",
      "Epoch 7/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6926 - loss: 0.9100\n",
      "Epoch 8/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6922 - loss: 0.8978\n",
      "Epoch 9/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7015 - loss: 0.8816\n",
      "Epoch 10/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6985 - loss: 0.8828\n",
      "Epoch 11/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7057 - loss: 0.8655\n",
      "Epoch 12/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7066 - loss: 0.8610\n",
      "Epoch 13/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7090 - loss: 0.8534\n",
      "Epoch 14/35\n",
      "33/33 - 1s - 22ms/step - accuracy: 0.7076 - loss: 0.8537\n",
      "Epoch 15/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7075 - loss: 0.8471\n",
      "Epoch 16/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7121 - loss: 0.8386\n",
      "Epoch 17/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7100 - loss: 0.8370\n",
      "Epoch 18/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7161 - loss: 0.8280\n",
      "Epoch 19/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7132 - loss: 0.8279\n",
      "Epoch 20/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7191 - loss: 0.8177\n",
      "Epoch 21/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7179 - loss: 0.8163\n",
      "Epoch 22/35\n",
      "33/33 - 1s - 21ms/step - accuracy: 0.7181 - loss: 0.8135\n",
      "Epoch 23/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.7204 - loss: 0.8110\n",
      "Epoch 24/35\n",
      "33/33 - 1s - 22ms/step - accuracy: 0.7251 - loss: 0.8077\n",
      "Epoch 25/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7246 - loss: 0.8042\n",
      "Epoch 26/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7241 - loss: 0.7994\n",
      "Epoch 27/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7275 - loss: 0.7933\n",
      "Epoch 28/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7280 - loss: 0.7904\n",
      "Epoch 29/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7272 - loss: 0.7911\n",
      "Epoch 30/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7273 - loss: 0.7866\n",
      "Epoch 31/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7254 - loss: 0.7897\n",
      "Epoch 32/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7310 - loss: 0.7833\n",
      "Epoch 33/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7253 - loss: 0.7809\n",
      "Epoch 34/35\n",
      "33/33 - 1s - 22ms/step - accuracy: 0.7336 - loss: 0.7749\n",
      "Epoch 35/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7344 - loss: 0.7759\n",
      "9/9 - 0s - 32ms/step\n",
      "Epoch 1/35\n",
      "33/33 - 2s - 63ms/step - accuracy: 0.6098 - loss: 1.3703\n",
      "Epoch 2/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6479 - loss: 1.0925\n",
      "Epoch 3/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6590 - loss: 1.0370\n",
      "Epoch 4/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6709 - loss: 0.9960\n",
      "Epoch 5/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6755 - loss: 0.9640\n",
      "Epoch 6/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6823 - loss: 0.9436\n",
      "Epoch 7/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6913 - loss: 0.9140\n",
      "Epoch 8/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6914 - loss: 0.9011\n",
      "Epoch 9/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6994 - loss: 0.8837\n",
      "Epoch 10/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7004 - loss: 0.8760\n",
      "Epoch 11/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7069 - loss: 0.8660\n",
      "Epoch 12/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7059 - loss: 0.8605\n",
      "Epoch 13/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7099 - loss: 0.8514\n",
      "Epoch 14/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7090 - loss: 0.8453\n",
      "Epoch 15/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7128 - loss: 0.8351\n",
      "Epoch 16/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7129 - loss: 0.8391\n",
      "Epoch 17/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7117 - loss: 0.8321\n",
      "Epoch 18/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7170 - loss: 0.8247\n",
      "Epoch 19/35\n",
      "33/33 - 1s - 21ms/step - accuracy: 0.7185 - loss: 0.8207\n",
      "Epoch 20/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7171 - loss: 0.8213\n",
      "Epoch 21/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7184 - loss: 0.8160\n",
      "Epoch 22/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7211 - loss: 0.8085\n",
      "Epoch 23/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7240 - loss: 0.8033\n",
      "Epoch 24/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7245 - loss: 0.8027\n",
      "Epoch 25/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7298 - loss: 0.7946\n",
      "Epoch 26/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7281 - loss: 0.7966\n",
      "Epoch 27/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7269 - loss: 0.7962\n",
      "Epoch 28/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7271 - loss: 0.7881\n",
      "Epoch 29/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7259 - loss: 0.7850\n",
      "Epoch 30/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7248 - loss: 0.7918\n",
      "Epoch 31/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7280 - loss: 0.7884\n",
      "Epoch 32/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7286 - loss: 0.7771\n",
      "Epoch 33/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7322 - loss: 0.7798\n",
      "Epoch 34/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7357 - loss: 0.7713\n",
      "Epoch 35/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7362 - loss: 0.7674\n",
      "9/9 - 0s - 34ms/step\n",
      "Epoch 1/35\n",
      "33/33 - 2s - 54ms/step - accuracy: 0.6178 - loss: 1.5725\n",
      "Epoch 2/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6556 - loss: 1.0646\n",
      "Epoch 3/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6579 - loss: 1.0283\n",
      "Epoch 4/35\n",
      "33/33 - 1s - 21ms/step - accuracy: 0.6684 - loss: 0.9992\n",
      "Epoch 5/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6740 - loss: 0.9743\n",
      "Epoch 6/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6764 - loss: 0.9556\n",
      "Epoch 7/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6802 - loss: 0.9346\n",
      "Epoch 8/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6866 - loss: 0.9203\n",
      "Epoch 9/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6903 - loss: 0.9084\n",
      "Epoch 10/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.6938 - loss: 0.9022\n",
      "Epoch 11/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6935 - loss: 0.8989\n",
      "Epoch 12/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6963 - loss: 0.8829\n",
      "Epoch 13/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6966 - loss: 0.8801\n",
      "Epoch 14/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7002 - loss: 0.8706\n",
      "Epoch 15/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.6964 - loss: 0.8678\n",
      "Epoch 16/35\n",
      "33/33 - 1s - 18ms/step - accuracy: 0.7026 - loss: 0.8625\n",
      "Epoch 17/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7017 - loss: 0.8571\n",
      "Epoch 18/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7065 - loss: 0.8512\n",
      "Epoch 19/35\n",
      "33/33 - 1s - 17ms/step - accuracy: 0.7093 - loss: 0.8447\n",
      "Epoch 20/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7054 - loss: 0.8475\n",
      "Epoch 21/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7076 - loss: 0.8403\n",
      "Epoch 22/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7099 - loss: 0.8325\n",
      "Epoch 23/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7121 - loss: 0.8292\n",
      "Epoch 24/35\n",
      "33/33 - 1s - 20ms/step - accuracy: 0.7131 - loss: 0.8286\n",
      "Epoch 25/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7097 - loss: 0.8319\n",
      "Epoch 26/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7166 - loss: 0.8232\n",
      "Epoch 27/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7139 - loss: 0.8176\n",
      "Epoch 28/35\n",
      "33/33 - 1s - 15ms/step - accuracy: 0.7177 - loss: 0.8162\n",
      "Epoch 29/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7192 - loss: 0.8105\n",
      "Epoch 30/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7181 - loss: 0.8104\n",
      "Epoch 31/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7205 - loss: 0.8087\n",
      "Epoch 32/35\n",
      "33/33 - 1s - 15ms/step - accuracy: 0.7207 - loss: 0.8030\n",
      "Epoch 33/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7229 - loss: 0.8023\n",
      "Epoch 34/35\n",
      "33/33 - 1s - 16ms/step - accuracy: 0.7224 - loss: 0.8042\n",
      "Epoch 35/35\n",
      "33/33 - 1s - 15ms/step - accuracy: 0.7236 - loss: 0.7948\n",
      "9/9 - 0s - 30ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.7449   \u001b[0m | \u001b[0m0.0497   \u001b[0m | \u001b[0m426.2    \u001b[0m | \u001b[0m0.7069   \u001b[0m | \u001b[0m0.2187   \u001b[0m | \u001b[0m35.43    \u001b[0m | \u001b[0m1.148    \u001b[0m | \u001b[0m1.717    \u001b[0m | \u001b[0m1.232    \u001b[0m | \u001b[0m0.8645   \u001b[0m | \u001b[0m66.1     \u001b[0m | \u001b[0m0.3309   \u001b[0m | \u001b[0m0.4449   \u001b[0m |\n",
      "Epoch 1/38\n",
      "60/60 - 3s - 56ms/step - accuracy: 0.2184 - loss: 2.5341\n",
      "Epoch 2/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2377 - loss: 2.5218\n",
      "Epoch 3/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2567 - loss: 2.5077\n",
      "Epoch 4/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2706 - loss: 2.4945\n",
      "Epoch 5/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2889 - loss: 2.4783\n",
      "Epoch 6/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3047 - loss: 2.4630\n",
      "Epoch 7/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3190 - loss: 2.4465\n",
      "Epoch 8/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.3472 - loss: 2.4301\n",
      "Epoch 9/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3612 - loss: 2.4141\n",
      "Epoch 10/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3759 - loss: 2.3980\n",
      "Epoch 11/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3910 - loss: 2.3809\n",
      "Epoch 12/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4088 - loss: 2.3646\n",
      "Epoch 13/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4318 - loss: 2.3462\n",
      "Epoch 14/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4417 - loss: 2.3295\n",
      "Epoch 15/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4599 - loss: 2.3100\n",
      "Epoch 16/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4705 - loss: 2.2925\n",
      "Epoch 17/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4819 - loss: 2.2739\n",
      "Epoch 18/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4956 - loss: 2.2556\n",
      "Epoch 19/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5063 - loss: 2.2363\n",
      "Epoch 20/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5172 - loss: 2.2175\n",
      "Epoch 21/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5266 - loss: 2.1986\n",
      "Epoch 22/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5339 - loss: 2.1782\n",
      "Epoch 23/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5471 - loss: 2.1599\n",
      "Epoch 24/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5497 - loss: 2.1428\n",
      "Epoch 25/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5554 - loss: 2.1227\n",
      "Epoch 26/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5654 - loss: 2.1032\n",
      "Epoch 27/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.5702 - loss: 2.0840\n",
      "Epoch 28/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5746 - loss: 2.0648\n",
      "Epoch 29/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5791 - loss: 2.0452\n",
      "Epoch 30/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5841 - loss: 2.0269\n",
      "Epoch 31/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5916 - loss: 2.0070\n",
      "Epoch 32/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5946 - loss: 1.9891\n",
      "Epoch 33/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5947 - loss: 1.9694\n",
      "Epoch 34/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6021 - loss: 1.9488\n",
      "Epoch 35/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6059 - loss: 1.9339\n",
      "Epoch 36/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6060 - loss: 1.9129\n",
      "Epoch 37/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6099 - loss: 1.8923\n",
      "Epoch 38/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6137 - loss: 1.8739\n",
      "15/15 - 0s - 22ms/step\n",
      "Epoch 1/38\n",
      "60/60 - 3s - 55ms/step - accuracy: 0.0411 - loss: 2.6726\n",
      "Epoch 2/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0471 - loss: 2.6576\n",
      "Epoch 3/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0506 - loss: 2.6441\n",
      "Epoch 4/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0635 - loss: 2.6285\n",
      "Epoch 5/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0707 - loss: 2.6143\n",
      "Epoch 6/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0783 - loss: 2.5989\n",
      "Epoch 7/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.0927 - loss: 2.5830\n",
      "Epoch 8/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1097 - loss: 2.5671\n",
      "Epoch 9/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1237 - loss: 2.5512\n",
      "Epoch 10/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1436 - loss: 2.5329\n",
      "Epoch 11/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1580 - loss: 2.5175\n",
      "Epoch 12/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1805 - loss: 2.5003\n",
      "Epoch 13/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2038 - loss: 2.4814\n",
      "Epoch 14/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2224 - loss: 2.4643\n",
      "Epoch 15/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2509 - loss: 2.4461\n",
      "Epoch 16/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2771 - loss: 2.4264\n",
      "Epoch 17/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2992 - loss: 2.4089\n",
      "Epoch 18/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3302 - loss: 2.3877\n",
      "Epoch 19/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3490 - loss: 2.3696\n",
      "Epoch 20/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3738 - loss: 2.3499\n",
      "Epoch 21/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4026 - loss: 2.3291\n",
      "Epoch 22/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4231 - loss: 2.3087\n",
      "Epoch 23/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4400 - loss: 2.2909\n",
      "Epoch 24/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4607 - loss: 2.2696\n",
      "Epoch 25/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.4760 - loss: 2.2490\n",
      "Epoch 26/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4915 - loss: 2.2292\n",
      "Epoch 27/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5070 - loss: 2.2093\n",
      "Epoch 28/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5211 - loss: 2.1895\n",
      "Epoch 29/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5327 - loss: 2.1696\n",
      "Epoch 30/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5426 - loss: 2.1491\n",
      "Epoch 31/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5513 - loss: 2.1282\n",
      "Epoch 32/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5582 - loss: 2.1073\n",
      "Epoch 33/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5650 - loss: 2.0884\n",
      "Epoch 34/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5705 - loss: 2.0682\n",
      "Epoch 35/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5733 - loss: 2.0478\n",
      "Epoch 36/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5788 - loss: 2.0277\n",
      "Epoch 37/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5844 - loss: 2.0064\n",
      "Epoch 38/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5913 - loss: 1.9870\n",
      "15/15 - 0s - 21ms/step\n",
      "Epoch 1/38\n",
      "60/60 - 4s - 66ms/step - accuracy: 0.0916 - loss: 2.6599\n",
      "Epoch 2/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1092 - loss: 2.6442\n",
      "Epoch 3/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1192 - loss: 2.6307\n",
      "Epoch 4/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.1407 - loss: 2.6149\n",
      "Epoch 5/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1622 - loss: 2.5987\n",
      "Epoch 6/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1784 - loss: 2.5827\n",
      "Epoch 7/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2079 - loss: 2.5660\n",
      "Epoch 8/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2327 - loss: 2.5498\n",
      "Epoch 9/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2599 - loss: 2.5307\n",
      "Epoch 10/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2834 - loss: 2.5128\n",
      "Epoch 11/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3169 - loss: 2.4953\n",
      "Epoch 12/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3477 - loss: 2.4756\n",
      "Epoch 13/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3731 - loss: 2.4588\n",
      "Epoch 14/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4005 - loss: 2.4392\n",
      "Epoch 15/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4326 - loss: 2.4189\n",
      "Epoch 16/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4588 - loss: 2.4007\n",
      "Epoch 17/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4805 - loss: 2.3808\n",
      "Epoch 18/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5052 - loss: 2.3610\n",
      "Epoch 19/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5266 - loss: 2.3410\n",
      "Epoch 20/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5406 - loss: 2.3226\n",
      "Epoch 21/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5598 - loss: 2.3012\n",
      "Epoch 22/38\n",
      "60/60 - 1s - 15ms/step - accuracy: 0.5746 - loss: 2.2805\n",
      "Epoch 23/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5872 - loss: 2.2592\n",
      "Epoch 24/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6001 - loss: 2.2396\n",
      "Epoch 25/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6078 - loss: 2.2184\n",
      "Epoch 26/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6184 - loss: 2.1978\n",
      "Epoch 27/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6221 - loss: 2.1777\n",
      "Epoch 28/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6263 - loss: 2.1586\n",
      "Epoch 29/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6308 - loss: 2.1366\n",
      "Epoch 30/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6359 - loss: 2.1150\n",
      "Epoch 31/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6384 - loss: 2.0933\n",
      "Epoch 32/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6389 - loss: 2.0729\n",
      "Epoch 33/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6414 - loss: 2.0528\n",
      "Epoch 34/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6431 - loss: 2.0299\n",
      "Epoch 35/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6431 - loss: 2.0112\n",
      "Epoch 36/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6436 - loss: 1.9898\n",
      "Epoch 37/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6433 - loss: 1.9706\n",
      "Epoch 38/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6441 - loss: 1.9521\n",
      "15/15 - 0s - 23ms/step\n",
      "Epoch 1/38\n",
      "60/60 - 3s - 58ms/step - accuracy: 0.1364 - loss: 2.5838\n",
      "Epoch 2/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1510 - loss: 2.5699\n",
      "Epoch 3/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1645 - loss: 2.5529\n",
      "Epoch 4/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1797 - loss: 2.5389\n",
      "Epoch 5/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.1981 - loss: 2.5238\n",
      "Epoch 6/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2173 - loss: 2.5069\n",
      "Epoch 7/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2341 - loss: 2.4906\n",
      "Epoch 8/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2506 - loss: 2.4753\n",
      "Epoch 9/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2702 - loss: 2.4571\n",
      "Epoch 10/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.2895 - loss: 2.4381\n",
      "Epoch 11/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3092 - loss: 2.4210\n",
      "Epoch 12/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3363 - loss: 2.4021\n",
      "Epoch 13/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3550 - loss: 2.3832\n",
      "Epoch 14/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3673 - loss: 2.3642\n",
      "Epoch 15/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.3874 - loss: 2.3448\n",
      "Epoch 16/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4055 - loss: 2.3252\n",
      "Epoch 17/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4225 - loss: 2.3062\n",
      "Epoch 18/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.4407 - loss: 2.2863\n",
      "Epoch 19/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4560 - loss: 2.2671\n",
      "Epoch 20/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4728 - loss: 2.2465\n",
      "Epoch 21/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4878 - loss: 2.2266\n",
      "Epoch 22/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4971 - loss: 2.2073\n",
      "Epoch 23/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5100 - loss: 2.1875\n",
      "Epoch 24/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5280 - loss: 2.1670\n",
      "Epoch 25/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5402 - loss: 2.1469\n",
      "Epoch 26/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5519 - loss: 2.1258\n",
      "Epoch 27/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5615 - loss: 2.1066\n",
      "Epoch 28/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5726 - loss: 2.0864\n",
      "Epoch 29/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5831 - loss: 2.0669\n",
      "Epoch 30/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5847 - loss: 2.0463\n",
      "Epoch 31/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5937 - loss: 2.0268\n",
      "Epoch 32/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5993 - loss: 2.0047\n",
      "Epoch 33/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6063 - loss: 1.9855\n",
      "Epoch 34/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6102 - loss: 1.9674\n",
      "Epoch 35/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.6134 - loss: 1.9472\n",
      "Epoch 36/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.6168 - loss: 1.9270\n",
      "Epoch 37/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6232 - loss: 1.9079\n",
      "Epoch 38/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6249 - loss: 1.8883\n",
      "15/15 - 0s - 20ms/step\n",
      "Epoch 1/38\n",
      "60/60 - 3s - 58ms/step - accuracy: 0.0153 - loss: 2.7947\n",
      "Epoch 2/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0186 - loss: 2.7795\n",
      "Epoch 3/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.0208 - loss: 2.7657\n",
      "Epoch 4/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.0252 - loss: 2.7500\n",
      "Epoch 5/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0257 - loss: 2.7363\n",
      "Epoch 6/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.0333 - loss: 2.7201\n",
      "Epoch 7/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.0417 - loss: 2.7028\n",
      "Epoch 8/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0497 - loss: 2.6847\n",
      "Epoch 9/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.0585 - loss: 2.6720\n",
      "Epoch 10/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.0702 - loss: 2.6520\n",
      "Epoch 11/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.0832 - loss: 2.6330\n",
      "Epoch 12/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1058 - loss: 2.6134\n",
      "Epoch 13/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.1223 - loss: 2.5968\n",
      "Epoch 14/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1405 - loss: 2.5781\n",
      "Epoch 15/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1661 - loss: 2.5595\n",
      "Epoch 16/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.1914 - loss: 2.5394\n",
      "Epoch 17/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2200 - loss: 2.5193\n",
      "Epoch 18/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2444 - loss: 2.4997\n",
      "Epoch 19/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.2751 - loss: 2.4783\n",
      "Epoch 20/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3038 - loss: 2.4608\n",
      "Epoch 21/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3312 - loss: 2.4400\n",
      "Epoch 22/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.3659 - loss: 2.4192\n",
      "Epoch 23/38\n",
      "60/60 - 1s - 13ms/step - accuracy: 0.3874 - loss: 2.3994\n",
      "Epoch 24/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4107 - loss: 2.3808\n",
      "Epoch 25/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.4402 - loss: 2.3591\n",
      "Epoch 26/38\n",
      "60/60 - 1s - 13ms/step - accuracy: 0.4632 - loss: 2.3368\n",
      "Epoch 27/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.4814 - loss: 2.3172\n",
      "Epoch 28/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5057 - loss: 2.2966\n",
      "Epoch 29/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5235 - loss: 2.2744\n",
      "Epoch 30/38\n",
      "60/60 - 1s - 14ms/step - accuracy: 0.5416 - loss: 2.2543\n",
      "Epoch 31/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5540 - loss: 2.2337\n",
      "Epoch 32/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5646 - loss: 2.2123\n",
      "Epoch 33/38\n",
      "60/60 - 1s - 11ms/step - accuracy: 0.5795 - loss: 2.1905\n",
      "Epoch 34/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5901 - loss: 2.1700\n",
      "Epoch 35/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.5972 - loss: 2.1487\n",
      "Epoch 36/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6025 - loss: 2.1272\n",
      "Epoch 37/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6095 - loss: 2.1061\n",
      "Epoch 38/38\n",
      "60/60 - 1s - 12ms/step - accuracy: 0.6147 - loss: 2.0867\n",
      "15/15 - 0s - 23ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.799    \u001b[0m | \u001b[0m230.1    \u001b[0m | \u001b[0m0.7296   \u001b[0m | \u001b[0m0.1913   \u001b[0m | \u001b[0m37.74    \u001b[0m | \u001b[0m1.944    \u001b[0m | \u001b[0m1.239    \u001b[0m | \u001b[0m2.426    \u001b[0m | \u001b[0m0.7632   \u001b[0m | \u001b[0m60.51    \u001b[0m | \u001b[0m0.771    \u001b[0m | \u001b[0m3.457    \u001b[0m |\n",
      "Epoch 1/21\n",
      "51/51 - 3s - 56ms/step - accuracy: 0.6172 - loss: 1.2904\n",
      "Epoch 2/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.6873 - loss: 0.9453\n",
      "Epoch 3/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7025 - loss: 0.8822\n",
      "Epoch 4/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7166 - loss: 0.8386\n",
      "Epoch 5/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7257 - loss: 0.8058\n",
      "Epoch 6/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7348 - loss: 0.7843\n",
      "Epoch 7/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7409 - loss: 0.7619\n",
      "Epoch 8/21\n",
      "51/51 - 0s - 9ms/step - accuracy: 0.7472 - loss: 0.7465\n",
      "Epoch 9/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7494 - loss: 0.7300\n",
      "Epoch 10/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7544 - loss: 0.7143\n",
      "Epoch 11/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7598 - loss: 0.7008\n",
      "Epoch 12/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7619 - loss: 0.6911\n",
      "Epoch 13/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7679 - loss: 0.6779\n",
      "Epoch 14/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7707 - loss: 0.6689\n",
      "Epoch 15/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7724 - loss: 0.6573\n",
      "Epoch 16/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7766 - loss: 0.6469\n",
      "Epoch 17/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7784 - loss: 0.6380\n",
      "Epoch 18/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7810 - loss: 0.6287\n",
      "Epoch 19/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7821 - loss: 0.6216\n",
      "Epoch 20/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7862 - loss: 0.6131\n",
      "Epoch 21/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7889 - loss: 0.6061\n",
      "13/13 - 0s - 23ms/step\n",
      "Epoch 1/21\n",
      "51/51 - 3s - 65ms/step - accuracy: 0.5856 - loss: 1.2913\n",
      "Epoch 2/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7011 - loss: 0.8939\n",
      "Epoch 3/21\n",
      "51/51 - 0s - 9ms/step - accuracy: 0.7161 - loss: 0.8506\n",
      "Epoch 4/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7253 - loss: 0.8220\n",
      "Epoch 5/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7325 - loss: 0.7971\n",
      "Epoch 6/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7399 - loss: 0.7758\n",
      "Epoch 7/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7446 - loss: 0.7573\n",
      "Epoch 8/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7484 - loss: 0.7410\n",
      "Epoch 9/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7534 - loss: 0.7269\n",
      "Epoch 10/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7598 - loss: 0.7100\n",
      "Epoch 11/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7637 - loss: 0.6964\n",
      "Epoch 12/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7661 - loss: 0.6870\n",
      "Epoch 13/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7685 - loss: 0.6743\n",
      "Epoch 14/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7738 - loss: 0.6615\n",
      "Epoch 15/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7773 - loss: 0.6521\n",
      "Epoch 16/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7798 - loss: 0.6425\n",
      "Epoch 17/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7820 - loss: 0.6339\n",
      "Epoch 18/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7841 - loss: 0.6253\n",
      "Epoch 19/21\n",
      "51/51 - 0s - 10ms/step - accuracy: 0.7845 - loss: 0.6174\n",
      "Epoch 20/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7881 - loss: 0.6073\n",
      "Epoch 21/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7927 - loss: 0.5974\n",
      "13/13 - 0s - 25ms/step\n",
      "Epoch 1/21\n",
      "51/51 - 3s - 52ms/step - accuracy: 0.6114 - loss: 1.3551\n",
      "Epoch 2/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.6861 - loss: 0.9462\n",
      "Epoch 3/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7046 - loss: 0.8865\n",
      "Epoch 4/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7158 - loss: 0.8500\n",
      "Epoch 5/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7246 - loss: 0.8221\n",
      "Epoch 6/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7277 - loss: 0.7999\n",
      "Epoch 7/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7375 - loss: 0.7794\n",
      "Epoch 8/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7389 - loss: 0.7622\n",
      "Epoch 9/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7452 - loss: 0.7455\n",
      "Epoch 10/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7508 - loss: 0.7294\n",
      "Epoch 11/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7549 - loss: 0.7143\n",
      "Epoch 12/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7603 - loss: 0.7004\n",
      "Epoch 13/21\n",
      "51/51 - 0s - 10ms/step - accuracy: 0.7625 - loss: 0.6884\n",
      "Epoch 14/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7672 - loss: 0.6778\n",
      "Epoch 15/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7713 - loss: 0.6663\n",
      "Epoch 16/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7736 - loss: 0.6541\n",
      "Epoch 17/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7777 - loss: 0.6434\n",
      "Epoch 18/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7816 - loss: 0.6345\n",
      "Epoch 19/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7845 - loss: 0.6253\n",
      "Epoch 20/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7849 - loss: 0.6166\n",
      "Epoch 21/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7890 - loss: 0.6087\n",
      "13/13 - 0s - 20ms/step\n",
      "Epoch 1/21\n",
      "51/51 - 3s - 51ms/step - accuracy: 0.6039 - loss: 1.2849\n",
      "Epoch 2/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.6813 - loss: 0.9383\n",
      "Epoch 3/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7019 - loss: 0.8805\n",
      "Epoch 4/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7150 - loss: 0.8410\n",
      "Epoch 5/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7266 - loss: 0.8085\n",
      "Epoch 6/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7349 - loss: 0.7814\n",
      "Epoch 7/21\n",
      "51/51 - 0s - 9ms/step - accuracy: 0.7438 - loss: 0.7583\n",
      "Epoch 8/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7508 - loss: 0.7398\n",
      "Epoch 9/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7574 - loss: 0.7217\n",
      "Epoch 10/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7603 - loss: 0.7055\n",
      "Epoch 11/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7672 - loss: 0.6932\n",
      "Epoch 12/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7701 - loss: 0.6796\n",
      "Epoch 13/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7723 - loss: 0.6716\n",
      "Epoch 14/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7760 - loss: 0.6547\n",
      "Epoch 15/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7803 - loss: 0.6453\n",
      "Epoch 16/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7832 - loss: 0.6349\n",
      "Epoch 17/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7885 - loss: 0.6245\n",
      "Epoch 18/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7914 - loss: 0.6159\n",
      "Epoch 19/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7893 - loss: 0.6092\n",
      "Epoch 20/21\n",
      "51/51 - 0s - 9ms/step - accuracy: 0.7938 - loss: 0.6002\n",
      "Epoch 21/21\n",
      "51/51 - 0s - 8ms/step - accuracy: 0.7975 - loss: 0.5923\n",
      "13/13 - 0s - 25ms/step\n",
      "Epoch 1/21\n",
      "51/51 - 3s - 61ms/step - accuracy: 0.5780 - loss: 1.4901\n",
      "Epoch 2/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.6879 - loss: 0.9335\n",
      "Epoch 3/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7044 - loss: 0.8823\n",
      "Epoch 4/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7124 - loss: 0.8488\n",
      "Epoch 5/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7216 - loss: 0.8216\n",
      "Epoch 6/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7279 - loss: 0.7985\n",
      "Epoch 7/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7339 - loss: 0.7793\n",
      "Epoch 8/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7398 - loss: 0.7628\n",
      "Epoch 9/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7434 - loss: 0.7474\n",
      "Epoch 10/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7495 - loss: 0.7330\n",
      "Epoch 11/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7542 - loss: 0.7202\n",
      "Epoch 12/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7575 - loss: 0.7074\n",
      "Epoch 13/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7607 - loss: 0.6975\n",
      "Epoch 14/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7647 - loss: 0.6861\n",
      "Epoch 15/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7667 - loss: 0.6766\n",
      "Epoch 16/21\n",
      "51/51 - 0s - 10ms/step - accuracy: 0.7731 - loss: 0.6665\n",
      "Epoch 17/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7734 - loss: 0.6585\n",
      "Epoch 18/21\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7752 - loss: 0.6500\n",
      "Epoch 19/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7760 - loss: 0.6440\n",
      "Epoch 20/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7799 - loss: 0.6349\n",
      "Epoch 21/21\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7813 - loss: 0.6282\n",
      "13/13 - 0s - 22ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7812   \u001b[0m | \u001b[0m4.705    \u001b[0m | \u001b[0m271.0    \u001b[0m | \u001b[0m0.02542  \u001b[0m | \u001b[0m0.03237  \u001b[0m | \u001b[0m20.63    \u001b[0m | \u001b[0m2.273    \u001b[0m | \u001b[0m1.629    \u001b[0m | \u001b[0m2.017    \u001b[0m | \u001b[0m0.9085   \u001b[0m | \u001b[0m32.44    \u001b[0m | \u001b[0m0.4104   \u001b[0m | \u001b[0m5.289    \u001b[0m |\n",
      "Epoch 1/39\n",
      "106/106 - 3s - 30ms/step - accuracy: 0.5881 - loss: 1.6535\n",
      "Epoch 2/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.2016\n",
      "Epoch 3/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1591\n",
      "Epoch 4/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1404\n",
      "Epoch 5/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1266\n",
      "Epoch 6/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1149\n",
      "Epoch 7/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1042\n",
      "Epoch 8/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0949\n",
      "Epoch 9/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0861\n",
      "Epoch 10/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0784\n",
      "Epoch 11/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0718\n",
      "Epoch 12/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0657\n",
      "Epoch 13/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0614\n",
      "Epoch 14/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0563\n",
      "Epoch 15/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0522\n",
      "Epoch 16/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0490\n",
      "Epoch 17/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0458\n",
      "Epoch 18/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0431\n",
      "Epoch 19/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0405\n",
      "Epoch 20/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0385\n",
      "Epoch 21/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0358\n",
      "Epoch 22/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6438 - loss: 1.0337\n",
      "Epoch 23/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6438 - loss: 1.0321\n",
      "Epoch 24/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6438 - loss: 1.0291\n",
      "Epoch 25/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6438 - loss: 1.0277\n",
      "Epoch 26/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6441 - loss: 1.0256\n",
      "Epoch 27/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6435 - loss: 1.0237\n",
      "Epoch 28/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6427 - loss: 1.0220\n",
      "Epoch 29/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6422 - loss: 1.0200\n",
      "Epoch 30/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6425 - loss: 1.0187\n",
      "Epoch 31/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6419 - loss: 1.0169\n",
      "Epoch 32/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6417 - loss: 1.0158\n",
      "Epoch 33/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6429 - loss: 1.0140\n",
      "Epoch 34/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6426 - loss: 1.0124\n",
      "Epoch 35/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6427 - loss: 1.0108\n",
      "Epoch 36/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6429 - loss: 1.0093\n",
      "Epoch 37/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6425 - loss: 1.0074\n",
      "Epoch 38/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6430 - loss: 1.0060\n",
      "Epoch 39/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6449 - loss: 1.0044\n",
      "27/27 - 0s - 18ms/step\n",
      "Epoch 1/39\n",
      "106/106 - 3s - 26ms/step - accuracy: 0.5403 - loss: 1.7415\n",
      "Epoch 2/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.2388\n",
      "Epoch 3/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1882\n",
      "Epoch 4/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1704\n",
      "Epoch 5/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1594\n",
      "Epoch 6/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1503\n",
      "Epoch 7/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1419\n",
      "Epoch 8/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1334\n",
      "Epoch 9/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1246\n",
      "Epoch 10/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1149\n",
      "Epoch 11/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1048\n",
      "Epoch 12/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0948\n",
      "Epoch 13/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0855\n",
      "Epoch 14/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6446 - loss: 1.0766\n",
      "Epoch 15/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6455 - loss: 1.0690\n",
      "Epoch 16/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6465 - loss: 1.0629\n",
      "Epoch 17/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6492 - loss: 1.0573\n",
      "Epoch 18/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6517 - loss: 1.0524\n",
      "Epoch 19/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6533 - loss: 1.0484\n",
      "Epoch 20/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6557 - loss: 1.0449\n",
      "Epoch 21/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6568 - loss: 1.0416\n",
      "Epoch 22/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6585 - loss: 1.0385\n",
      "Epoch 23/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6593 - loss: 1.0351\n",
      "Epoch 24/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6601 - loss: 1.0326\n",
      "Epoch 25/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6623 - loss: 1.0293\n",
      "Epoch 26/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6624 - loss: 1.0276\n",
      "Epoch 27/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6664 - loss: 1.0237\n",
      "Epoch 28/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6678 - loss: 1.0205\n",
      "Epoch 29/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6681 - loss: 1.0177\n",
      "Epoch 30/39\n",
      "106/106 - 1s - 9ms/step - accuracy: 0.6690 - loss: 1.0146\n",
      "Epoch 31/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6715 - loss: 1.0113\n",
      "Epoch 32/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6733 - loss: 1.0091\n",
      "Epoch 33/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6748 - loss: 1.0063\n",
      "Epoch 34/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6751 - loss: 1.0032\n",
      "Epoch 35/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6762 - loss: 1.0001\n",
      "Epoch 36/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6776 - loss: 0.9987\n",
      "Epoch 37/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6771 - loss: 0.9954\n",
      "Epoch 38/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6785 - loss: 0.9926\n",
      "Epoch 39/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6796 - loss: 0.9904\n",
      "27/27 - 0s - 17ms/step\n",
      "Epoch 1/39\n",
      "106/106 - 3s - 25ms/step - accuracy: 0.3594 - loss: 2.2412\n",
      "Epoch 2/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.2763\n",
      "Epoch 3/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1931\n",
      "Epoch 4/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1688\n",
      "Epoch 5/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.1551\n",
      "Epoch 6/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1446\n",
      "Epoch 7/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1355\n",
      "Epoch 8/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1263\n",
      "Epoch 9/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1180\n",
      "Epoch 10/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1094\n",
      "Epoch 11/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1016\n",
      "Epoch 12/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0944\n",
      "Epoch 13/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0871\n",
      "Epoch 14/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0808\n",
      "Epoch 15/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0747\n",
      "Epoch 16/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0692\n",
      "Epoch 17/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0638\n",
      "Epoch 18/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0591\n",
      "Epoch 19/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0547\n",
      "Epoch 20/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0511\n",
      "Epoch 21/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0477\n",
      "Epoch 22/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0446\n",
      "Epoch 23/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0419\n",
      "Epoch 24/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0387\n",
      "Epoch 25/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0365\n",
      "Epoch 26/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6441 - loss: 1.0347\n",
      "Epoch 27/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6441 - loss: 1.0314\n",
      "Epoch 28/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6451 - loss: 1.0296\n",
      "Epoch 29/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6452 - loss: 1.0268\n",
      "Epoch 30/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6462 - loss: 1.0244\n",
      "Epoch 31/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6479 - loss: 1.0235\n",
      "Epoch 32/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6485 - loss: 1.0204\n",
      "Epoch 33/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6523 - loss: 1.0189\n",
      "Epoch 34/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6507 - loss: 1.0167\n",
      "Epoch 35/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6550 - loss: 1.0151\n",
      "Epoch 36/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6576 - loss: 1.0133\n",
      "Epoch 37/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6569 - loss: 1.0114\n",
      "Epoch 38/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6601 - loss: 1.0094\n",
      "Epoch 39/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6615 - loss: 1.0078\n",
      "27/27 - 0s - 15ms/step\n",
      "Epoch 1/39\n",
      "106/106 - 3s - 28ms/step - accuracy: 0.2812 - loss: 2.4586\n",
      "Epoch 2/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.3497\n",
      "Epoch 3/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.2288\n",
      "Epoch 4/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.1927\n",
      "Epoch 5/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1740\n",
      "Epoch 6/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1614\n",
      "Epoch 7/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.1514\n",
      "Epoch 8/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1428\n",
      "Epoch 9/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.1350\n",
      "Epoch 10/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.1273\n",
      "Epoch 11/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.1197\n",
      "Epoch 12/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.1124\n",
      "Epoch 13/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.1049\n",
      "Epoch 14/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0975\n",
      "Epoch 15/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0906\n",
      "Epoch 16/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0832\n",
      "Epoch 17/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0765\n",
      "Epoch 18/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0698\n",
      "Epoch 19/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0635\n",
      "Epoch 20/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0575\n",
      "Epoch 21/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0523\n",
      "Epoch 22/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6440 - loss: 1.0468\n",
      "Epoch 23/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.0420\n",
      "Epoch 24/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0374\n",
      "Epoch 25/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0325\n",
      "Epoch 26/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6440 - loss: 1.0283\n",
      "Epoch 27/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0242\n",
      "Epoch 28/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0208\n",
      "Epoch 29/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6440 - loss: 1.0163\n",
      "Epoch 30/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6442 - loss: 1.0132\n",
      "Epoch 31/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6442 - loss: 1.0089\n",
      "Epoch 32/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6443 - loss: 1.0058\n",
      "Epoch 33/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6442 - loss: 1.0031\n",
      "Epoch 34/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 0.9999\n",
      "Epoch 35/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6448 - loss: 0.9965\n",
      "Epoch 36/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6445 - loss: 0.9946\n",
      "Epoch 37/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6447 - loss: 0.9912\n",
      "Epoch 38/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6444 - loss: 0.9891\n",
      "Epoch 39/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6445 - loss: 0.9879\n",
      "27/27 - 0s - 17ms/step\n",
      "Epoch 1/39\n",
      "106/106 - 3s - 27ms/step - accuracy: 0.5220 - loss: 1.7857\n",
      "Epoch 2/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.2592\n",
      "Epoch 3/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1980\n",
      "Epoch 4/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.1753\n",
      "Epoch 5/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1617\n",
      "Epoch 6/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1514\n",
      "Epoch 7/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.1426\n",
      "Epoch 8/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.1350\n",
      "Epoch 9/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.1275\n",
      "Epoch 10/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.1201\n",
      "Epoch 11/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.1127\n",
      "Epoch 12/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.1052\n",
      "Epoch 13/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0975\n",
      "Epoch 14/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0899\n",
      "Epoch 15/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0817\n",
      "Epoch 16/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0739\n",
      "Epoch 17/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0668\n",
      "Epoch 18/39\n",
      "106/106 - 1s - 8ms/step - accuracy: 0.6439 - loss: 1.0594\n",
      "Epoch 19/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0527\n",
      "Epoch 20/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6439 - loss: 1.0462\n",
      "Epoch 21/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0408\n",
      "Epoch 22/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6439 - loss: 1.0351\n",
      "Epoch 23/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6436 - loss: 1.0298\n",
      "Epoch 24/39\n",
      "106/106 - 1s - 9ms/step - accuracy: 0.6446 - loss: 1.0253\n",
      "Epoch 25/39\n",
      "106/106 - 1s - 11ms/step - accuracy: 0.6461 - loss: 1.0201\n",
      "Epoch 26/39\n",
      "106/106 - 1s - 9ms/step - accuracy: 0.6495 - loss: 1.0162\n",
      "Epoch 27/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6508 - loss: 1.0119\n",
      "Epoch 28/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6529 - loss: 1.0078\n",
      "Epoch 29/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6553 - loss: 1.0048\n",
      "Epoch 30/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6569 - loss: 1.0006\n",
      "Epoch 31/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6581 - loss: 0.9972\n",
      "Epoch 32/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6601 - loss: 0.9928\n",
      "Epoch 33/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6611 - loss: 0.9907\n",
      "Epoch 34/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6619 - loss: 0.9870\n",
      "Epoch 35/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6654 - loss: 0.9834\n",
      "Epoch 36/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6673 - loss: 0.9807\n",
      "Epoch 37/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6699 - loss: 0.9777\n",
      "Epoch 38/39\n",
      "106/106 - 1s - 6ms/step - accuracy: 0.6712 - loss: 0.9752\n",
      "Epoch 39/39\n",
      "106/106 - 1s - 7ms/step - accuracy: 0.6720 - loss: 0.9727\n",
      "27/27 - 0s - 18ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6614   \u001b[0m | \u001b[0m2.059    \u001b[0m | \u001b[0m130.8    \u001b[0m | \u001b[0m0.2898   \u001b[0m | \u001b[0m0.04837  \u001b[0m | \u001b[0m38.59    \u001b[0m | \u001b[0m2.616    \u001b[0m | \u001b[0m2.267    \u001b[0m | \u001b[0m2.743    \u001b[0m | \u001b[0m0.8056   \u001b[0m | \u001b[0m26.79    \u001b[0m | \u001b[0m0.8926   \u001b[0m | \u001b[0m3.775    \u001b[0m |\n",
      "Epoch 1/25\n",
      "31/31 - 4s - 124ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/25\n",
      "31/31 - 1s - 27ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "8/8 - 0s - 55ms/step\n",
      "Epoch 1/25\n",
      "31/31 - 4s - 116ms/step - accuracy: 0.6282 - loss: nan\n",
      "Epoch 2/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/25\n",
      "31/31 - 1s - 28ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "8/8 - 0s - 50ms/step\n",
      "Epoch 1/25\n",
      "31/31 - 4s - 123ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/25\n",
      "31/31 - 1s - 28ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/25\n",
      "31/31 - 1s - 27ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "8/8 - 0s - 55ms/step\n",
      "Epoch 1/25\n",
      "31/31 - 4s - 129ms/step - accuracy: 0.6245 - loss: nan\n",
      "Epoch 2/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/25\n",
      "31/31 - 1s - 28ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/25\n",
      "31/31 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/25\n",
      "31/31 - 1s - 29ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "8/8 - 0s - 56ms/step\n",
      "Epoch 1/25\n",
      "31/31 - 4s - 114ms/step - accuracy: 0.6435 - loss: nan\n",
      "Epoch 2/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/25\n",
      "31/31 - 1s - 28ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 11/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 12/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 13/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 14/25\n",
      "31/31 - 1s - 24ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 15/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 16/25\n",
      "31/31 - 1s - 28ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 17/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 18/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 19/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 20/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 21/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 22/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 23/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 24/25\n",
      "31/31 - 1s - 23ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 25/25\n",
      "31/31 - 1s - 22ms/step - accuracy: 0.6439 - loss: nan\n",
      "8/8 - 0s - 58ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.644    \u001b[0m | \u001b[0m7.267    \u001b[0m | \u001b[0m458.4    \u001b[0m | \u001b[0m0.318    \u001b[0m | \u001b[0m0.03302  \u001b[0m | \u001b[0m24.56    \u001b[0m | \u001b[0m1.854    \u001b[0m | \u001b[0m2.636    \u001b[0m | \u001b[0m2.721    \u001b[0m | \u001b[0m0.01688  \u001b[0m | \u001b[0m55.97    \u001b[0m | \u001b[0m0.4174   \u001b[0m | \u001b[0m1.555    \u001b[0m |\n",
      "Epoch 1/30\n",
      "59/59 - 4s - 68ms/step - accuracy: 0.6241 - loss: 1.2782\n",
      "Epoch 2/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1662\n",
      "Epoch 3/30\n",
      "59/59 - 1s - 11ms/step - accuracy: 0.6440 - loss: 1.1661\n",
      "Epoch 4/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1667\n",
      "Epoch 5/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.1664\n",
      "Epoch 6/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.1655\n",
      "Epoch 7/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1648\n",
      "Epoch 8/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1647\n",
      "Epoch 9/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1625\n",
      "Epoch 10/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1574\n",
      "Epoch 11/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1415\n",
      "Epoch 12/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.0994\n",
      "Epoch 13/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.0545\n",
      "Epoch 14/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6381 - loss: 1.0319\n",
      "Epoch 15/30\n",
      "59/59 - 1s - 11ms/step - accuracy: 0.6389 - loss: 1.0177\n",
      "Epoch 16/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6388 - loss: 1.0040\n",
      "Epoch 17/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6432 - loss: 0.9893\n",
      "Epoch 18/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6480 - loss: 0.9774\n",
      "Epoch 19/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6493 - loss: 0.9646\n",
      "Epoch 20/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6531 - loss: 0.9548\n",
      "Epoch 21/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6546 - loss: 0.9446\n",
      "Epoch 22/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6539 - loss: 0.9359\n",
      "Epoch 23/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6576 - loss: 0.9242\n",
      "Epoch 24/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6646 - loss: 0.9130\n",
      "Epoch 25/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6677 - loss: 0.9017\n",
      "Epoch 26/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6730 - loss: 0.8911\n",
      "Epoch 27/30\n",
      "59/59 - 1s - 11ms/step - accuracy: 0.6794 - loss: 0.8763\n",
      "Epoch 28/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6844 - loss: 0.8649\n",
      "Epoch 29/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6950 - loss: 0.8502\n",
      "Epoch 30/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6993 - loss: 0.8406\n",
      "15/15 - 0s - 22ms/step\n",
      "Epoch 1/30\n",
      "59/59 - 2s - 42ms/step - accuracy: 0.5981 - loss: 1.3362\n",
      "Epoch 2/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1665\n",
      "Epoch 3/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1666\n",
      "Epoch 4/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1652\n",
      "Epoch 5/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1669\n",
      "Epoch 6/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1653\n",
      "Epoch 7/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1660\n",
      "Epoch 8/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1643\n",
      "Epoch 9/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.6440 - loss: 1.1634\n",
      "Epoch 10/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1631\n",
      "Epoch 11/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1578\n",
      "Epoch 12/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1401\n",
      "Epoch 13/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.0861\n",
      "Epoch 14/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6417 - loss: 1.0453\n",
      "Epoch 15/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6389 - loss: 1.0236\n",
      "Epoch 16/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6419 - loss: 1.0029\n",
      "Epoch 17/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6552 - loss: 0.9802\n",
      "Epoch 18/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6644 - loss: 0.9591\n",
      "Epoch 19/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6706 - loss: 0.9422\n",
      "Epoch 20/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6738 - loss: 0.9296\n",
      "Epoch 21/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.6734 - loss: 0.9170\n",
      "Epoch 22/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6762 - loss: 0.9045\n",
      "Epoch 23/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6772 - loss: 0.8915\n",
      "Epoch 24/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6822 - loss: 0.8816\n",
      "Epoch 25/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6917 - loss: 0.8665\n",
      "Epoch 26/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7011 - loss: 0.8545\n",
      "Epoch 27/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.7054 - loss: 0.8398\n",
      "Epoch 28/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7109 - loss: 0.8294\n",
      "Epoch 29/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7144 - loss: 0.8168\n",
      "Epoch 30/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7191 - loss: 0.8062\n",
      "15/15 - 0s - 19ms/step\n",
      "Epoch 1/30\n",
      "59/59 - 2s - 37ms/step - accuracy: 0.6339 - loss: 1.2864\n",
      "Epoch 2/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1670\n",
      "Epoch 3/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1672\n",
      "Epoch 4/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1652\n",
      "Epoch 5/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1666\n",
      "Epoch 6/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1661\n",
      "Epoch 7/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1660\n",
      "Epoch 8/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1664\n",
      "Epoch 9/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1661\n",
      "Epoch 10/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1645\n",
      "Epoch 11/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1639\n",
      "Epoch 12/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1622\n",
      "Epoch 13/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1561\n",
      "Epoch 14/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1279\n",
      "Epoch 15/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.6443 - loss: 1.0651\n",
      "Epoch 16/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6385 - loss: 1.0262\n",
      "Epoch 17/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6424 - loss: 1.0016\n",
      "Epoch 18/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6511 - loss: 0.9737\n",
      "Epoch 19/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6604 - loss: 0.9493\n",
      "Epoch 20/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6677 - loss: 0.9264\n",
      "Epoch 21/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6715 - loss: 0.9102\n",
      "Epoch 22/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6749 - loss: 0.8952\n",
      "Epoch 23/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6842 - loss: 0.8809\n",
      "Epoch 24/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6911 - loss: 0.8656\n",
      "Epoch 25/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6987 - loss: 0.8512\n",
      "Epoch 26/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7046 - loss: 0.8366\n",
      "Epoch 27/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.7113 - loss: 0.8219\n",
      "Epoch 28/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7149 - loss: 0.8090\n",
      "Epoch 29/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7182 - loss: 0.7985\n",
      "Epoch 30/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7244 - loss: 0.7863\n",
      "15/15 - 0s - 20ms/step\n",
      "Epoch 1/30\n",
      "59/59 - 2s - 37ms/step - accuracy: 0.6127 - loss: 1.2530\n",
      "Epoch 2/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1673\n",
      "Epoch 3/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1664\n",
      "Epoch 4/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1658\n",
      "Epoch 5/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1656\n",
      "Epoch 6/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1664\n",
      "Epoch 7/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1652\n",
      "Epoch 8/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1644\n",
      "Epoch 9/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6440 - loss: 1.1638\n",
      "Epoch 10/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1622\n",
      "Epoch 11/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1568\n",
      "Epoch 12/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6440 - loss: 1.1368\n",
      "Epoch 13/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6438 - loss: 1.0882\n",
      "Epoch 14/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6432 - loss: 1.0502\n",
      "Epoch 15/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6405 - loss: 1.0277\n",
      "Epoch 16/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6401 - loss: 1.0081\n",
      "Epoch 17/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.6458 - loss: 0.9893\n",
      "Epoch 18/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6603 - loss: 0.9695\n",
      "Epoch 19/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6638 - loss: 0.9509\n",
      "Epoch 20/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6665 - loss: 0.9348\n",
      "Epoch 21/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.6709 - loss: 0.9165\n",
      "Epoch 22/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6758 - loss: 0.9040\n",
      "Epoch 23/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6772 - loss: 0.8908\n",
      "Epoch 24/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6820 - loss: 0.8815\n",
      "Epoch 25/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6896 - loss: 0.8716\n",
      "Epoch 26/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6895 - loss: 0.8629\n",
      "Epoch 27/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6959 - loss: 0.8532\n",
      "Epoch 28/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6995 - loss: 0.8418\n",
      "Epoch 29/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7060 - loss: 0.8295\n",
      "Epoch 30/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7162 - loss: 0.8160\n",
      "15/15 - 0s - 22ms/step\n",
      "Epoch 1/30\n",
      "59/59 - 2s - 39ms/step - accuracy: 0.6045 - loss: 1.3084\n",
      "Epoch 2/30\n",
      "59/59 - 1s - 9ms/step - accuracy: 0.6439 - loss: 1.1675\n",
      "Epoch 3/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1659\n",
      "Epoch 4/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1659\n",
      "Epoch 5/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.6439 - loss: 1.1661\n",
      "Epoch 6/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1658\n",
      "Epoch 7/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1647\n",
      "Epoch 8/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1651\n",
      "Epoch 9/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1652\n",
      "Epoch 10/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1653\n",
      "Epoch 11/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1630\n",
      "Epoch 12/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1620\n",
      "Epoch 13/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6439 - loss: 1.1555\n",
      "Epoch 14/30\n",
      "59/59 - 1s - 11ms/step - accuracy: 0.6439 - loss: 1.1325\n",
      "Epoch 15/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6442 - loss: 1.0777\n",
      "Epoch 16/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6415 - loss: 1.0371\n",
      "Epoch 17/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6445 - loss: 1.0114\n",
      "Epoch 18/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6501 - loss: 0.9872\n",
      "Epoch 19/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6649 - loss: 0.9609\n",
      "Epoch 20/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6686 - loss: 0.9419\n",
      "Epoch 21/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6717 - loss: 0.9266\n",
      "Epoch 22/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6737 - loss: 0.9136\n",
      "Epoch 23/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6764 - loss: 0.9005\n",
      "Epoch 24/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6854 - loss: 0.8843\n",
      "Epoch 25/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.6923 - loss: 0.8717\n",
      "Epoch 26/30\n",
      "59/59 - 1s - 10ms/step - accuracy: 0.6991 - loss: 0.8577\n",
      "Epoch 27/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7042 - loss: 0.8450\n",
      "Epoch 28/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7094 - loss: 0.8335\n",
      "Epoch 29/30\n",
      "59/59 - 0s - 7ms/step - accuracy: 0.7153 - loss: 0.8230\n",
      "Epoch 30/30\n",
      "59/59 - 0s - 8ms/step - accuracy: 0.7174 - loss: 0.8111\n",
      "15/15 - 0s - 18ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.7179   \u001b[0m | \u001b[0m1.079    \u001b[0m | \u001b[0m235.0    \u001b[0m | \u001b[0m0.9429   \u001b[0m | \u001b[0m0.09696  \u001b[0m | \u001b[0m30.38    \u001b[0m | \u001b[0m2.406    \u001b[0m | \u001b[0m1.727    \u001b[0m | \u001b[0m2.944    \u001b[0m | \u001b[0m0.9628   \u001b[0m | \u001b[0m32.66    \u001b[0m | \u001b[0m0.4972   \u001b[0m | \u001b[0m2.106    \u001b[0m |\n",
      "Epoch 1/21\n",
      "120/120 - 3s - 25ms/step - accuracy: 0.6832 - loss: 0.9678\n",
      "Epoch 2/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7536 - loss: 0.7196\n",
      "Epoch 3/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7765 - loss: 0.6523\n",
      "Epoch 4/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7852 - loss: 0.6192\n",
      "Epoch 5/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7980 - loss: 0.5841\n",
      "Epoch 6/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8075 - loss: 0.5551\n",
      "Epoch 7/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8143 - loss: 0.5281\n",
      "Epoch 8/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8229 - loss: 0.5014\n",
      "Epoch 9/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8299 - loss: 0.4858\n",
      "Epoch 10/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8377 - loss: 0.4644\n",
      "Epoch 11/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8408 - loss: 0.4475\n",
      "Epoch 12/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8497 - loss: 0.4300\n",
      "Epoch 13/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8529 - loss: 0.4139\n",
      "Epoch 14/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8588 - loss: 0.3964\n",
      "Epoch 15/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8639 - loss: 0.3890\n",
      "Epoch 16/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8666 - loss: 0.3779\n",
      "Epoch 17/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8677 - loss: 0.3697\n",
      "Epoch 18/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8785 - loss: 0.3493\n",
      "Epoch 19/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8781 - loss: 0.3489\n",
      "Epoch 20/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8793 - loss: 0.3413\n",
      "Epoch 21/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8847 - loss: 0.3259\n",
      "30/30 - 0s - 13ms/step\n",
      "Epoch 1/21\n",
      "120/120 - 4s - 32ms/step - accuracy: 0.6916 - loss: 0.9825\n",
      "Epoch 2/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7579 - loss: 0.7186\n",
      "Epoch 3/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7754 - loss: 0.6541\n",
      "Epoch 4/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7884 - loss: 0.6127\n",
      "Epoch 5/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7967 - loss: 0.5827\n",
      "Epoch 6/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8076 - loss: 0.5533\n",
      "Epoch 7/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8134 - loss: 0.5255\n",
      "Epoch 8/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8207 - loss: 0.5075\n",
      "Epoch 9/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8277 - loss: 0.4849\n",
      "Epoch 10/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8369 - loss: 0.4670\n",
      "Epoch 11/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8420 - loss: 0.4481\n",
      "Epoch 12/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8444 - loss: 0.4331\n",
      "Epoch 13/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8512 - loss: 0.4196\n",
      "Epoch 14/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8566 - loss: 0.4081\n",
      "Epoch 15/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8596 - loss: 0.3947\n",
      "Epoch 16/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8646 - loss: 0.3881\n",
      "Epoch 17/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8675 - loss: 0.3732\n",
      "Epoch 18/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8712 - loss: 0.3613\n",
      "Epoch 19/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8760 - loss: 0.3521\n",
      "Epoch 20/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8783 - loss: 0.3422\n",
      "Epoch 21/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8818 - loss: 0.3337\n",
      "30/30 - 0s - 14ms/step\n",
      "Epoch 1/21\n",
      "120/120 - 3s - 27ms/step - accuracy: 0.6820 - loss: 1.0059\n",
      "Epoch 2/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7480 - loss: 0.7411\n",
      "Epoch 3/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7696 - loss: 0.6743\n",
      "Epoch 4/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7845 - loss: 0.6318\n",
      "Epoch 5/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7945 - loss: 0.5905\n",
      "Epoch 6/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8030 - loss: 0.5604\n",
      "Epoch 7/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8113 - loss: 0.5380\n",
      "Epoch 8/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8169 - loss: 0.5146\n",
      "Epoch 9/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8269 - loss: 0.4927\n",
      "Epoch 10/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8336 - loss: 0.4677\n",
      "Epoch 11/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8444 - loss: 0.4471\n",
      "Epoch 12/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8471 - loss: 0.4322\n",
      "Epoch 13/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8522 - loss: 0.4164\n",
      "Epoch 14/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8592 - loss: 0.3977\n",
      "Epoch 15/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8645 - loss: 0.3902\n",
      "Epoch 16/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8680 - loss: 0.3725\n",
      "Epoch 17/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8699 - loss: 0.3674\n",
      "Epoch 18/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8750 - loss: 0.3470\n",
      "Epoch 19/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8797 - loss: 0.3370\n",
      "Epoch 20/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8857 - loss: 0.3257\n",
      "Epoch 21/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8872 - loss: 0.3206\n",
      "30/30 - 0s - 15ms/step\n",
      "Epoch 1/21\n",
      "120/120 - 3s - 26ms/step - accuracy: 0.6829 - loss: 0.9829\n",
      "Epoch 2/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7493 - loss: 0.7280\n",
      "Epoch 3/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7739 - loss: 0.6549\n",
      "Epoch 4/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.7882 - loss: 0.6068\n",
      "Epoch 5/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8009 - loss: 0.5762\n",
      "Epoch 6/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8089 - loss: 0.5496\n",
      "Epoch 7/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8192 - loss: 0.5206\n",
      "Epoch 8/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8263 - loss: 0.4934\n",
      "Epoch 9/21\n",
      "120/120 - 1s - 7ms/step - accuracy: 0.8384 - loss: 0.4716\n",
      "Epoch 10/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8455 - loss: 0.4453\n",
      "Epoch 11/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8521 - loss: 0.4231\n",
      "Epoch 12/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8554 - loss: 0.4108\n",
      "Epoch 13/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8621 - loss: 0.3916\n",
      "Epoch 14/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8665 - loss: 0.3825\n",
      "Epoch 15/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8673 - loss: 0.3719\n",
      "Epoch 16/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8744 - loss: 0.3552\n",
      "Epoch 17/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8768 - loss: 0.3462\n",
      "Epoch 18/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8840 - loss: 0.3327\n",
      "Epoch 19/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8875 - loss: 0.3209\n",
      "Epoch 20/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8924 - loss: 0.3137\n",
      "Epoch 21/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8919 - loss: 0.3060\n",
      "30/30 - 0s - 15ms/step\n",
      "Epoch 1/21\n",
      "120/120 - 4s - 31ms/step - accuracy: 0.6846 - loss: 0.9877\n",
      "Epoch 2/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7450 - loss: 0.7291\n",
      "Epoch 3/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.7733 - loss: 0.6511\n",
      "Epoch 4/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.7898 - loss: 0.6051\n",
      "Epoch 5/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.7980 - loss: 0.5685\n",
      "Epoch 6/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8069 - loss: 0.5402\n",
      "Epoch 7/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8176 - loss: 0.5159\n",
      "Epoch 8/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8227 - loss: 0.4943\n",
      "Epoch 9/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8322 - loss: 0.4716\n",
      "Epoch 10/21\n",
      "120/120 - 1s - 11ms/step - accuracy: 0.8394 - loss: 0.4514\n",
      "Epoch 11/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8430 - loss: 0.4365\n",
      "Epoch 12/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8466 - loss: 0.4258\n",
      "Epoch 13/21\n",
      "120/120 - 1s - 11ms/step - accuracy: 0.8529 - loss: 0.4054\n",
      "Epoch 14/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8606 - loss: 0.3926\n",
      "Epoch 15/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8662 - loss: 0.3787\n",
      "Epoch 16/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8705 - loss: 0.3722\n",
      "Epoch 17/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8721 - loss: 0.3580\n",
      "Epoch 18/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8723 - loss: 0.3525\n",
      "Epoch 19/21\n",
      "120/120 - 1s - 9ms/step - accuracy: 0.8781 - loss: 0.3415\n",
      "Epoch 20/21\n",
      "120/120 - 1s - 8ms/step - accuracy: 0.8816 - loss: 0.3327\n",
      "Epoch 21/21\n",
      "120/120 - 1s - 10ms/step - accuracy: 0.8824 - loss: 0.3242\n",
      "30/30 - 0s - 15ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8703   \u001b[0m | \u001b[0m2.564    \u001b[0m | \u001b[0m114.8    \u001b[0m | \u001b[0m0.6096   \u001b[0m | \u001b[0m0.1508   \u001b[0m | \u001b[0m21.03    \u001b[0m | \u001b[0m1.557    \u001b[0m | \u001b[0m2.817    \u001b[0m | \u001b[0m1.479    \u001b[0m | \u001b[0m0.1534   \u001b[0m | \u001b[0m54.05    \u001b[0m | \u001b[0m0.9857   \u001b[0m | \u001b[0m1.694    \u001b[0m |\n",
      "Epoch 1/27\n",
      "34/34 - 4s - 123ms/step - accuracy: 0.6588 - loss: 1.0976\n",
      "Epoch 2/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7270 - loss: 0.8051\n",
      "Epoch 3/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7486 - loss: 0.7340\n",
      "Epoch 4/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7698 - loss: 0.6774\n",
      "Epoch 5/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7781 - loss: 0.6511\n",
      "Epoch 6/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7895 - loss: 0.6116\n",
      "Epoch 7/27\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.7969 - loss: 0.5814\n",
      "Epoch 8/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7988 - loss: 0.5676\n",
      "Epoch 9/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8107 - loss: 0.5364\n",
      "Epoch 10/27\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.8152 - loss: 0.5161\n",
      "Epoch 11/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8237 - loss: 0.4948\n",
      "Epoch 12/27\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8247 - loss: 0.4795\n",
      "Epoch 13/27\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8319 - loss: 0.4668\n",
      "Epoch 14/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8423 - loss: 0.4344\n",
      "Epoch 15/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8501 - loss: 0.4120\n",
      "Epoch 16/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8582 - loss: 0.3904\n",
      "Epoch 17/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8553 - loss: 0.3952\n",
      "Epoch 18/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8617 - loss: 0.3720\n",
      "Epoch 19/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8733 - loss: 0.3495\n",
      "Epoch 20/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.8747 - loss: 0.3423\n",
      "Epoch 21/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8839 - loss: 0.3202\n",
      "Epoch 22/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8898 - loss: 0.3053\n",
      "Epoch 23/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8891 - loss: 0.3060\n",
      "Epoch 24/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8868 - loss: 0.3065\n",
      "Epoch 25/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8943 - loss: 0.2851\n",
      "Epoch 26/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9030 - loss: 0.2689\n",
      "Epoch 27/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9033 - loss: 0.2630\n",
      "9/9 - 0s - 41ms/step\n",
      "Epoch 1/27\n",
      "34/34 - 5s - 149ms/step - accuracy: 0.6708 - loss: 1.0110\n",
      "Epoch 2/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7457 - loss: 0.7621\n",
      "Epoch 3/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7587 - loss: 0.6984\n",
      "Epoch 4/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.7744 - loss: 0.6524\n",
      "Epoch 5/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7834 - loss: 0.6165\n",
      "Epoch 6/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7934 - loss: 0.5854\n",
      "Epoch 7/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8035 - loss: 0.5591\n",
      "Epoch 8/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8109 - loss: 0.5347\n",
      "Epoch 9/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8155 - loss: 0.5172\n",
      "Epoch 10/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8230 - loss: 0.4938\n",
      "Epoch 11/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8238 - loss: 0.4833\n",
      "Epoch 12/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8285 - loss: 0.4671\n",
      "Epoch 13/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8375 - loss: 0.4486\n",
      "Epoch 14/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.8417 - loss: 0.4336\n",
      "Epoch 15/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8428 - loss: 0.4269\n",
      "Epoch 16/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8530 - loss: 0.4021\n",
      "Epoch 17/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8592 - loss: 0.3875\n",
      "Epoch 18/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8628 - loss: 0.3726\n",
      "Epoch 19/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8675 - loss: 0.3652\n",
      "Epoch 20/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8748 - loss: 0.3426\n",
      "Epoch 21/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8818 - loss: 0.3232\n",
      "Epoch 22/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8876 - loss: 0.3137\n",
      "Epoch 23/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8896 - loss: 0.3030\n",
      "Epoch 24/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.8948 - loss: 0.2973\n",
      "Epoch 25/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8982 - loss: 0.2778\n",
      "Epoch 26/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8925 - loss: 0.2892\n",
      "Epoch 27/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9005 - loss: 0.2694\n",
      "9/9 - 0s - 40ms/step\n",
      "Epoch 1/27\n",
      "34/34 - 4s - 122ms/step - accuracy: 0.6307 - loss: 1.1911\n",
      "Epoch 2/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7137 - loss: 0.8303\n",
      "Epoch 3/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7378 - loss: 0.7573\n",
      "Epoch 4/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7617 - loss: 0.6900\n",
      "Epoch 5/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7730 - loss: 0.6490\n",
      "Epoch 6/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7845 - loss: 0.6135\n",
      "Epoch 7/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7903 - loss: 0.5935\n",
      "Epoch 8/27\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.7947 - loss: 0.5755\n",
      "Epoch 9/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8034 - loss: 0.5473\n",
      "Epoch 10/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8142 - loss: 0.5238\n",
      "Epoch 11/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8146 - loss: 0.5054\n",
      "Epoch 12/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8232 - loss: 0.4932\n",
      "Epoch 13/27\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.8278 - loss: 0.4752\n",
      "Epoch 14/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8290 - loss: 0.4647\n",
      "Epoch 15/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8374 - loss: 0.4462\n",
      "Epoch 16/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8418 - loss: 0.4298\n",
      "Epoch 17/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8479 - loss: 0.4124\n",
      "Epoch 18/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.8552 - loss: 0.3994\n",
      "Epoch 19/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8606 - loss: 0.3798\n",
      "Epoch 20/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8627 - loss: 0.3718\n",
      "Epoch 21/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8726 - loss: 0.3511\n",
      "Epoch 22/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8733 - loss: 0.3414\n",
      "Epoch 23/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8776 - loss: 0.3307\n",
      "Epoch 24/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8840 - loss: 0.3157\n",
      "Epoch 25/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8911 - loss: 0.2980\n",
      "Epoch 26/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8920 - loss: 0.2946\n",
      "Epoch 27/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8950 - loss: 0.2876\n",
      "9/9 - 0s - 42ms/step\n",
      "Epoch 1/27\n",
      "34/34 - 4s - 132ms/step - accuracy: 0.6529 - loss: 1.1254\n",
      "Epoch 2/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7373 - loss: 0.7897\n",
      "Epoch 3/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7613 - loss: 0.7106\n",
      "Epoch 4/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7737 - loss: 0.6609\n",
      "Epoch 5/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7859 - loss: 0.6192\n",
      "Epoch 6/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7906 - loss: 0.5919\n",
      "Epoch 7/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7989 - loss: 0.5697\n",
      "Epoch 8/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8083 - loss: 0.5438\n",
      "Epoch 9/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8099 - loss: 0.5272\n",
      "Epoch 10/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8217 - loss: 0.5030\n",
      "Epoch 11/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8300 - loss: 0.4779\n",
      "Epoch 12/27\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.8324 - loss: 0.4628\n",
      "Epoch 13/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8401 - loss: 0.4410\n",
      "Epoch 14/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8483 - loss: 0.4256\n",
      "Epoch 15/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8489 - loss: 0.4129\n",
      "Epoch 16/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8558 - loss: 0.3981\n",
      "Epoch 17/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8662 - loss: 0.3731\n",
      "Epoch 18/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8723 - loss: 0.3506\n",
      "Epoch 19/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8726 - loss: 0.3529\n",
      "Epoch 20/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8757 - loss: 0.3372\n",
      "Epoch 21/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8850 - loss: 0.3141\n",
      "Epoch 22/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.8913 - loss: 0.3003\n",
      "Epoch 23/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8993 - loss: 0.2800\n",
      "Epoch 24/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8996 - loss: 0.2796\n",
      "Epoch 25/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9008 - loss: 0.2675\n",
      "Epoch 26/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9055 - loss: 0.2650\n",
      "Epoch 27/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9076 - loss: 0.2542\n",
      "9/9 - 0s - 39ms/step\n",
      "Epoch 1/27\n",
      "34/34 - 4s - 114ms/step - accuracy: 0.6564 - loss: 1.0635\n",
      "Epoch 2/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7266 - loss: 0.8051\n",
      "Epoch 3/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7571 - loss: 0.7107\n",
      "Epoch 4/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.7747 - loss: 0.6511\n",
      "Epoch 5/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.7887 - loss: 0.6078\n",
      "Epoch 6/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.7940 - loss: 0.5845\n",
      "Epoch 7/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8024 - loss: 0.5611\n",
      "Epoch 8/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8126 - loss: 0.5279\n",
      "Epoch 9/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8143 - loss: 0.5172\n",
      "Epoch 10/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8233 - loss: 0.4885\n",
      "Epoch 11/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8271 - loss: 0.4817\n",
      "Epoch 12/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8408 - loss: 0.4453\n",
      "Epoch 13/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8450 - loss: 0.4274\n",
      "Epoch 14/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8543 - loss: 0.4021\n",
      "Epoch 15/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8577 - loss: 0.3894\n",
      "Epoch 16/27\n",
      "34/34 - 1s - 32ms/step - accuracy: 0.8601 - loss: 0.3895\n",
      "Epoch 17/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8709 - loss: 0.3544\n",
      "Epoch 18/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8685 - loss: 0.3602\n",
      "Epoch 19/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8738 - loss: 0.3525\n",
      "Epoch 20/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8805 - loss: 0.3283\n",
      "Epoch 21/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8816 - loss: 0.3167\n",
      "Epoch 22/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8870 - loss: 0.3085\n",
      "Epoch 23/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.8954 - loss: 0.2846\n",
      "Epoch 24/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9014 - loss: 0.2749\n",
      "Epoch 25/27\n",
      "34/34 - 1s - 27ms/step - accuracy: 0.8998 - loss: 0.2730\n",
      "Epoch 26/27\n",
      "34/34 - 1s - 31ms/step - accuracy: 0.9031 - loss: 0.2675\n",
      "Epoch 27/27\n",
      "34/34 - 1s - 26ms/step - accuracy: 0.9072 - loss: 0.2494\n",
      "9/9 - 0s - 39ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8763   \u001b[0m | \u001b[0m6.049    \u001b[0m | \u001b[0m404.6    \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m0.2185   \u001b[0m | \u001b[0m27.36    \u001b[0m | \u001b[0m2.265    \u001b[0m | \u001b[0m2.267    \u001b[0m | \u001b[0m2.072    \u001b[0m | \u001b[0m0.09939  \u001b[0m | \u001b[0m85.18    \u001b[0m | \u001b[0m0.3208   \u001b[0m | \u001b[0m1.306    \u001b[0m |\n",
      "Epoch 1/30\n",
      "41/41 - 4s - 96ms/step - accuracy: 0.6125 - loss: 1.2426\n",
      "Epoch 2/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.6977 - loss: 0.9080\n",
      "Epoch 3/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.7292 - loss: 0.8030\n",
      "Epoch 4/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.7502 - loss: 0.7257\n",
      "Epoch 5/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.7700 - loss: 0.6685\n",
      "Epoch 6/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.7810 - loss: 0.6320\n",
      "Epoch 7/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.7944 - loss: 0.5908\n",
      "Epoch 8/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.8095 - loss: 0.5534\n",
      "Epoch 9/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.8171 - loss: 0.5198\n",
      "Epoch 10/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8293 - loss: 0.4840\n",
      "Epoch 11/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8376 - loss: 0.4562\n",
      "Epoch 12/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.8476 - loss: 0.4298\n",
      "Epoch 13/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.8563 - loss: 0.4011\n",
      "Epoch 14/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8592 - loss: 0.3942\n",
      "Epoch 15/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8702 - loss: 0.3670\n",
      "Epoch 16/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8800 - loss: 0.3439\n",
      "Epoch 17/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8846 - loss: 0.3380\n",
      "Epoch 18/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8894 - loss: 0.3154\n",
      "Epoch 19/30\n",
      "41/41 - 1s - 17ms/step - accuracy: 0.8906 - loss: 0.3155\n",
      "Epoch 20/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.8936 - loss: 0.3068\n",
      "Epoch 21/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9006 - loss: 0.2928\n",
      "Epoch 22/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9006 - loss: 0.2842\n",
      "Epoch 23/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9105 - loss: 0.2634\n",
      "Epoch 24/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9094 - loss: 0.2620\n",
      "Epoch 25/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9146 - loss: 0.2495\n",
      "Epoch 26/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9168 - loss: 0.2419\n",
      "Epoch 27/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9160 - loss: 0.2415\n",
      "Epoch 28/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9200 - loss: 0.2353\n",
      "Epoch 29/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9240 - loss: 0.2254\n",
      "Epoch 30/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.9232 - loss: 0.2280\n",
      "11/11 - 0s - 34ms/step\n",
      "Epoch 1/30\n",
      "41/41 - 4s - 106ms/step - accuracy: 0.5743 - loss: 1.2660\n",
      "Epoch 2/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.6945 - loss: 0.8743\n",
      "Epoch 3/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7264 - loss: 0.7826\n",
      "Epoch 4/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7468 - loss: 0.7171\n",
      "Epoch 5/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7651 - loss: 0.6618\n",
      "Epoch 6/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7868 - loss: 0.6106\n",
      "Epoch 7/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8014 - loss: 0.5611\n",
      "Epoch 8/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8182 - loss: 0.5185\n",
      "Epoch 9/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8259 - loss: 0.4839\n",
      "Epoch 10/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.8399 - loss: 0.4508\n",
      "Epoch 11/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8448 - loss: 0.4325\n",
      "Epoch 12/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8521 - loss: 0.4091\n",
      "Epoch 13/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8622 - loss: 0.3884\n",
      "Epoch 14/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8711 - loss: 0.3660\n",
      "Epoch 15/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8783 - loss: 0.3485\n",
      "Epoch 16/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8791 - loss: 0.3467\n",
      "Epoch 17/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8833 - loss: 0.3295\n",
      "Epoch 18/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8857 - loss: 0.3150\n",
      "Epoch 19/30\n",
      "41/41 - 1s - 15ms/step - accuracy: 0.8872 - loss: 0.3179\n",
      "Epoch 20/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8916 - loss: 0.3065\n",
      "Epoch 21/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8956 - loss: 0.2981\n",
      "Epoch 22/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8984 - loss: 0.2882\n",
      "Epoch 23/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8975 - loss: 0.2890\n",
      "Epoch 24/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9049 - loss: 0.2764\n",
      "Epoch 25/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9059 - loss: 0.2685\n",
      "Epoch 26/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9018 - loss: 0.2807\n",
      "Epoch 27/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9112 - loss: 0.2615\n",
      "Epoch 28/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9044 - loss: 0.2725\n",
      "Epoch 29/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.9097 - loss: 0.2609\n",
      "Epoch 30/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9078 - loss: 0.2629\n",
      "11/11 - 0s - 32ms/step\n",
      "Epoch 1/30\n",
      "41/41 - 4s - 93ms/step - accuracy: 0.6321 - loss: 1.1605\n",
      "Epoch 2/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7034 - loss: 0.8667\n",
      "Epoch 3/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7306 - loss: 0.7789\n",
      "Epoch 4/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7511 - loss: 0.7171\n",
      "Epoch 5/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7633 - loss: 0.6687\n",
      "Epoch 6/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7797 - loss: 0.6219\n",
      "Epoch 7/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7993 - loss: 0.5660\n",
      "Epoch 8/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8154 - loss: 0.5190\n",
      "Epoch 9/30\n",
      "41/41 - 1s - 15ms/step - accuracy: 0.8257 - loss: 0.4837\n",
      "Epoch 10/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8388 - loss: 0.4448\n",
      "Epoch 11/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8516 - loss: 0.4153\n",
      "Epoch 12/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8631 - loss: 0.3845\n",
      "Epoch 13/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8739 - loss: 0.3544\n",
      "Epoch 14/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8861 - loss: 0.3323\n",
      "Epoch 15/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8890 - loss: 0.3110\n",
      "Epoch 16/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8933 - loss: 0.3051\n",
      "Epoch 17/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8980 - loss: 0.2941\n",
      "Epoch 18/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9048 - loss: 0.2712\n",
      "Epoch 19/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.9069 - loss: 0.2657\n",
      "Epoch 20/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9126 - loss: 0.2457\n",
      "Epoch 21/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9124 - loss: 0.2492\n",
      "Epoch 22/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9201 - loss: 0.2216\n",
      "Epoch 23/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9262 - loss: 0.2110\n",
      "Epoch 24/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9328 - loss: 0.1929\n",
      "Epoch 25/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9336 - loss: 0.1891\n",
      "Epoch 26/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9322 - loss: 0.1926\n",
      "Epoch 27/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9354 - loss: 0.1841\n",
      "Epoch 28/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9320 - loss: 0.1873\n",
      "Epoch 29/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9407 - loss: 0.1637\n",
      "Epoch 30/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.9452 - loss: 0.1589\n",
      "11/11 - 0s - 31ms/step\n",
      "Epoch 1/30\n",
      "41/41 - 3s - 79ms/step - accuracy: 0.5902 - loss: 1.3382\n",
      "Epoch 2/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.6803 - loss: 0.9180\n",
      "Epoch 3/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7109 - loss: 0.8268\n",
      "Epoch 4/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7370 - loss: 0.7580\n",
      "Epoch 5/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7543 - loss: 0.6997\n",
      "Epoch 6/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7716 - loss: 0.6470\n",
      "Epoch 7/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.7892 - loss: 0.5981\n",
      "Epoch 8/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8062 - loss: 0.5518\n",
      "Epoch 9/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8194 - loss: 0.5110\n",
      "Epoch 10/30\n",
      "41/41 - 1s - 15ms/step - accuracy: 0.8314 - loss: 0.4762\n",
      "Epoch 11/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8428 - loss: 0.4381\n",
      "Epoch 12/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8578 - loss: 0.4048\n",
      "Epoch 13/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8679 - loss: 0.3702\n",
      "Epoch 14/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8762 - loss: 0.3454\n",
      "Epoch 15/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.8921 - loss: 0.3098\n",
      "Epoch 16/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8963 - loss: 0.3024\n",
      "Epoch 17/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9027 - loss: 0.2793\n",
      "Epoch 18/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9078 - loss: 0.2618\n",
      "Epoch 19/30\n",
      "41/41 - 1s - 15ms/step - accuracy: 0.9094 - loss: 0.2571\n",
      "Epoch 20/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9214 - loss: 0.2233\n",
      "Epoch 21/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9256 - loss: 0.2080\n",
      "Epoch 22/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9216 - loss: 0.2194\n",
      "Epoch 23/30\n",
      "41/41 - 0s - 11ms/step - accuracy: 0.9257 - loss: 0.2105\n",
      "Epoch 24/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9290 - loss: 0.1968\n",
      "Epoch 25/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9370 - loss: 0.1704\n",
      "Epoch 26/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9339 - loss: 0.1827\n",
      "Epoch 27/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9437 - loss: 0.1565\n",
      "Epoch 28/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9402 - loss: 0.1636\n",
      "Epoch 29/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.9463 - loss: 0.1548\n",
      "Epoch 30/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9492 - loss: 0.1422\n",
      "11/11 - 0s - 32ms/step\n",
      "Epoch 1/30\n",
      "41/41 - 4s - 93ms/step - accuracy: 0.6184 - loss: 1.2277\n",
      "Epoch 2/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.7028 - loss: 0.8745\n",
      "Epoch 3/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7315 - loss: 0.7804\n",
      "Epoch 4/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7537 - loss: 0.7147\n",
      "Epoch 5/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.7674 - loss: 0.6636\n",
      "Epoch 6/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7742 - loss: 0.6318\n",
      "Epoch 7/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.7972 - loss: 0.5795\n",
      "Epoch 8/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8068 - loss: 0.5447\n",
      "Epoch 9/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.8170 - loss: 0.5137\n",
      "Epoch 10/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8290 - loss: 0.4723\n",
      "Epoch 11/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8399 - loss: 0.4457\n",
      "Epoch 12/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8481 - loss: 0.4256\n",
      "Epoch 13/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8516 - loss: 0.4073\n",
      "Epoch 14/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8592 - loss: 0.3900\n",
      "Epoch 15/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8643 - loss: 0.3756\n",
      "Epoch 16/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.8776 - loss: 0.3449\n",
      "Epoch 17/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8786 - loss: 0.3427\n",
      "Epoch 18/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.8810 - loss: 0.3305\n",
      "Epoch 19/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.8903 - loss: 0.3125\n",
      "Epoch 20/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.8891 - loss: 0.3057\n",
      "Epoch 21/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.8935 - loss: 0.3019\n",
      "Epoch 22/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9016 - loss: 0.2812\n",
      "Epoch 23/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9018 - loss: 0.2769\n",
      "Epoch 24/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9069 - loss: 0.2688\n",
      "Epoch 25/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9015 - loss: 0.2771\n",
      "Epoch 26/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9080 - loss: 0.2599\n",
      "Epoch 27/30\n",
      "41/41 - 1s - 12ms/step - accuracy: 0.9048 - loss: 0.2661\n",
      "Epoch 28/30\n",
      "41/41 - 0s - 12ms/step - accuracy: 0.9078 - loss: 0.2562\n",
      "Epoch 29/30\n",
      "41/41 - 1s - 16ms/step - accuracy: 0.9145 - loss: 0.2398\n",
      "Epoch 30/30\n",
      "41/41 - 1s - 13ms/step - accuracy: 0.9158 - loss: 0.2401\n",
      "11/11 - 0s - 32ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8936   \u001b[0m | \u001b[0m0.367    \u001b[0m | \u001b[0m336.4    \u001b[0m | \u001b[0m0.6776   \u001b[0m | \u001b[0m0.004976 \u001b[0m | \u001b[0m30.24    \u001b[0m | \u001b[0m1.453    \u001b[0m | \u001b[0m2.29     \u001b[0m | \u001b[0m1.349    \u001b[0m | \u001b[0m0.694    \u001b[0m | \u001b[0m44.81    \u001b[0m | \u001b[0m0.9367   \u001b[0m | \u001b[0m0.9626   \u001b[0m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:306\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 306\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:27\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m#25\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:309\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m--> 309\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[0;32m    310\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:220\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[1;34m(self, utility_function)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    219\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constrained:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m    223\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[0;32m    253\u001b[0m     y,\n\u001b[0;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_X_y\u001b[39m(\n\u001b[0;32m   1155\u001b[0m     X,\n\u001b[0;32m   1156\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1172\u001b[0m ):\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Input validation for standard estimators.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \n\u001b[0;32m   1175\u001b[0m \u001b[38;5;124;03m    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03m    default, X is checked to be non-empty and containing only finite values.\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;124;03m    Standard input checks are also applied to y, such as checking that y\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;124;03m    does not have np.nan or np.inf targets. For multi-label y, set\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;124;03m    multi_output=True to allow 2D and sparse y. If the dtype of X is\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;124;03m    object, attempt converting to float, raising on failure.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m \n\u001b[0;32m   1182\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;124;03m    X : {ndarray, list, sparse matrix}\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m        Input data.\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m    y : {ndarray, list, sparse matrix}\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03m        Labels.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03m    accept_sparse : str, bool or list of str, default=False\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m        String[s] representing allowed sparse matrix formats, such as 'csc',\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m        'csr', etc. If the input is sparse but not in the allowed format,\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m        it will be converted to the first listed format. True allows the input\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;124;03m        to be any format. False means that a sparse matrix input will\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;124;03m        raise an error.\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \n\u001b[0;32m   1197\u001b[0m \u001b[38;5;124;03m    accept_large_sparse : bool, default=True\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03m        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m        accept_sparse, accept_large_sparse will cause it to be accepted only\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m        if its indices are stored with a 32-bit dtype.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \n\u001b[0;32m   1204\u001b[0m \u001b[38;5;124;03m    dtype : 'numeric', type, list of type or None, default='numeric'\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;124;03m        Data type of result. If None, the dtype of the input is preserved.\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m        If \"numeric\", dtype is preserved unless array.dtype is object.\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;124;03m        If dtype is a list of types, conversion on the first type is only\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;124;03m        performed if the dtype of the input is not in the list.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \n\u001b[0;32m   1210\u001b[0m \u001b[38;5;124;03m    order : {'F', 'C'}, default=None\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03m        Whether an array will be forced to be fortran or c-style. If\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m        `None`, then the input data's order is preserved when possible.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m    copy : bool, default=False\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;124;03m        Whether a forced copy will be triggered. If copy=False, a copy might\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;124;03m        be triggered by a conversion.\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \n\u001b[0;32m   1218\u001b[0m \u001b[38;5;124;03m    force_writeable : bool, default=False\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m        Whether to force the output array to be writeable. If True, the returned array\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m        is guaranteed to be writeable, which may require a copy. Otherwise the\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m        writeability of the input array is preserved.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \n\u001b[0;32m   1223\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.6\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \n\u001b[0;32m   1225\u001b[0m \u001b[38;5;124;03m    force_all_finite : bool or 'allow-nan', default=True\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m        Whether to raise an error on np.inf, np.nan, pd.NA in X. This parameter\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m        does not influence whether y can have np.inf, np.nan, pd.NA values.\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;124;03m        The possibilities are:\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \n\u001b[0;32m   1230\u001b[0m \u001b[38;5;124;03m        - True: Force all values of X to be finite.\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;124;03m        - False: accepts np.inf, np.nan, pd.NA in X.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03m        - 'allow-nan': accepts only np.nan or pd.NA values in X. Values cannot\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m          be infinite.\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \n\u001b[0;32m   1235\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;124;03m           ``force_all_finite`` accepts the string ``'allow-nan'``.\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.23\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m           Accepts `pd.NA` and converts it into `np.nan`\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \n\u001b[0;32m   1241\u001b[0m \u001b[38;5;124;03m    ensure_2d : bool, default=True\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;124;03m        Whether to raise a value error if X is not 2D.\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m \n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m    allow_nd : bool, default=False\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m        Whether to allow X.ndim > 2.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \n\u001b[0;32m   1247\u001b[0m \u001b[38;5;124;03m    multi_output : bool, default=False\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;124;03m        Whether to allow 2D y (array or sparse matrix). If false, y will be\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;124;03m        validated as a vector. y cannot have np.nan or np.inf values if\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;124;03m        multi_output=True.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \n\u001b[0;32m   1252\u001b[0m \u001b[38;5;124;03m    ensure_min_samples : int, default=1\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;124;03m        Make sure that X has a minimum number of samples in its first\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;124;03m        axis (rows for a 2D array).\u001b[39;00m\n\u001b[0;32m   1255\u001b[0m \n\u001b[0;32m   1256\u001b[0m \u001b[38;5;124;03m    ensure_min_features : int, default=1\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;124;03m        Make sure that the 2D array has some minimum number of features\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;124;03m        (columns). The default value of 1 rejects empty datasets.\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;124;03m        This check is only enforced when X has effectively 2 dimensions or\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m        is originally 1D and ``ensure_2d`` is True. Setting to 0 disables\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;124;03m        this check.\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m \n\u001b[0;32m   1263\u001b[0m \u001b[38;5;124;03m    y_numeric : bool, default=False\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m        Whether to ensure that y has a numeric type. If dtype of y is object,\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m        it is converted to float64. Should only be used for regression\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m        algorithms.\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \n\u001b[0;32m   1268\u001b[0m \u001b[38;5;124;03m    estimator : str or estimator instance, default=None\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;124;03m        If passed, include the name of the estimator in warning messages.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;124;03m    X_converted : object\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;124;03m        The converted and validated X.\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \n\u001b[0;32m   1276\u001b[0m \u001b[38;5;124;03m    y_converted : object\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;124;03m        The converted and validated y.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \n\u001b[1;32m-> 1279\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.utils.validation import check_X_y\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;124;03m    >>> X = [[1, 2], [3, 4], [5, 6]]\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    >>> y = [1, 2, 3]\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    >>> X, y = check_X_y(X, y)\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;124;03m    >>> X\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;124;03m    array([[1, 2],\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;124;03m          [3, 4],\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m          [5, 6]])\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3])\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1289\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_X_y\u001b[39m(\n\u001b[0;32m   1155\u001b[0m     X,\n\u001b[0;32m   1156\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1172\u001b[0m ):\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Input validation for standard estimators.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \n\u001b[0;32m   1175\u001b[0m \u001b[38;5;124;03m    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03m    default, X is checked to be non-empty and containing only finite values.\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;124;03m    Standard input checks are also applied to y, such as checking that y\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;124;03m    does not have np.nan or np.inf targets. For multi-label y, set\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;124;03m    multi_output=True to allow 2D and sparse y. If the dtype of X is\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;124;03m    object, attempt converting to float, raising on failure.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m \n\u001b[0;32m   1182\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;124;03m    X : {ndarray, list, sparse matrix}\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m        Input data.\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m    y : {ndarray, list, sparse matrix}\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03m        Labels.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03m    accept_sparse : str, bool or list of str, default=False\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m        String[s] representing allowed sparse matrix formats, such as 'csc',\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m        'csr', etc. If the input is sparse but not in the allowed format,\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m        it will be converted to the first listed format. True allows the input\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;124;03m        to be any format. False means that a sparse matrix input will\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;124;03m        raise an error.\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \n\u001b[0;32m   1197\u001b[0m \u001b[38;5;124;03m    accept_large_sparse : bool, default=True\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03m        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m        accept_sparse, accept_large_sparse will cause it to be accepted only\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m        if its indices are stored with a 32-bit dtype.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \n\u001b[0;32m   1204\u001b[0m \u001b[38;5;124;03m    dtype : 'numeric', type, list of type or None, default='numeric'\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;124;03m        Data type of result. If None, the dtype of the input is preserved.\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m        If \"numeric\", dtype is preserved unless array.dtype is object.\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;124;03m        If dtype is a list of types, conversion on the first type is only\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;124;03m        performed if the dtype of the input is not in the list.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \n\u001b[0;32m   1210\u001b[0m \u001b[38;5;124;03m    order : {'F', 'C'}, default=None\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03m        Whether an array will be forced to be fortran or c-style. If\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m        `None`, then the input data's order is preserved when possible.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m    copy : bool, default=False\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;124;03m        Whether a forced copy will be triggered. If copy=False, a copy might\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;124;03m        be triggered by a conversion.\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \n\u001b[0;32m   1218\u001b[0m \u001b[38;5;124;03m    force_writeable : bool, default=False\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m        Whether to force the output array to be writeable. If True, the returned array\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m        is guaranteed to be writeable, which may require a copy. Otherwise the\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m        writeability of the input array is preserved.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \n\u001b[0;32m   1223\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.6\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \n\u001b[0;32m   1225\u001b[0m \u001b[38;5;124;03m    force_all_finite : bool or 'allow-nan', default=True\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m        Whether to raise an error on np.inf, np.nan, pd.NA in X. This parameter\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m        does not influence whether y can have np.inf, np.nan, pd.NA values.\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;124;03m        The possibilities are:\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \n\u001b[0;32m   1230\u001b[0m \u001b[38;5;124;03m        - True: Force all values of X to be finite.\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;124;03m        - False: accepts np.inf, np.nan, pd.NA in X.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03m        - 'allow-nan': accepts only np.nan or pd.NA values in X. Values cannot\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m          be infinite.\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \n\u001b[0;32m   1235\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;124;03m           ``force_all_finite`` accepts the string ``'allow-nan'``.\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.23\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m           Accepts `pd.NA` and converts it into `np.nan`\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \n\u001b[0;32m   1241\u001b[0m \u001b[38;5;124;03m    ensure_2d : bool, default=True\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;124;03m        Whether to raise a value error if X is not 2D.\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m \n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m    allow_nd : bool, default=False\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m        Whether to allow X.ndim > 2.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \n\u001b[0;32m   1247\u001b[0m \u001b[38;5;124;03m    multi_output : bool, default=False\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;124;03m        Whether to allow 2D y (array or sparse matrix). If false, y will be\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;124;03m        validated as a vector. y cannot have np.nan or np.inf values if\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;124;03m        multi_output=True.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \n\u001b[0;32m   1252\u001b[0m \u001b[38;5;124;03m    ensure_min_samples : int, default=1\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;124;03m        Make sure that X has a minimum number of samples in its first\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;124;03m        axis (rows for a 2D array).\u001b[39;00m\n\u001b[0;32m   1255\u001b[0m \n\u001b[0;32m   1256\u001b[0m \u001b[38;5;124;03m    ensure_min_features : int, default=1\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;124;03m        Make sure that the 2D array has some minimum number of features\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;124;03m        (columns). The default value of 1 rejects empty datasets.\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;124;03m        This check is only enforced when X has effectively 2 dimensions or\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m        is originally 1D and ``ensure_2d`` is True. Setting to 0 disables\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;124;03m        this check.\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m \n\u001b[0;32m   1263\u001b[0m \u001b[38;5;124;03m    y_numeric : bool, default=False\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m        Whether to ensure that y has a numeric type. If dtype of y is object,\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m        it is converted to float64. Should only be used for regression\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m        algorithms.\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \n\u001b[0;32m   1268\u001b[0m \u001b[38;5;124;03m    estimator : str or estimator instance, default=None\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;124;03m        If passed, include the name of the estimator in warning messages.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;124;03m    X_converted : object\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;124;03m        The converted and validated X.\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \n\u001b[0;32m   1276\u001b[0m \u001b[38;5;124;03m    y_converted : object\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;124;03m        The converted and validated y.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.utils.validation import check_X_y\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;124;03m    >>> X = [[1, 2], [3, 4], [5, 6]]\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    >>> y = [1, 2, 3]\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    >>> X, y = check_X_y(X, y)\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;124;03m    >>> X\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;124;03m    array([[1, 2],\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;124;03m          [3, 4],\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m          [5, 6]])\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3])\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1037\u001b[0m             msg = (\n\u001b[0;32m   1038\u001b[0m                 f\"Expected a 2-dimensional container but got {type_if_series} \"\n\u001b[0;32m   1039\u001b[0m                 \"instead. Pass a DataFrame containing a single row (i.e. \"\n\u001b[0;32m   1040\u001b[0m                 \"single sample) or a single column (i.e. single feature) \"\n\u001b[0;32m   1041\u001b[0m                 \"instead.\"\n\u001b[0;32m   1042\u001b[0m             )\n\u001b[0;32m   1043\u001b[0m         else:\n\u001b[0;32m   1044\u001b[0m             msg = (\n\u001b[0;32m   1045\u001b[0m                 f\"Expected 2D array, got 1D array instead:\\narray={array}.\\n\"\n\u001b[0;32m   1046\u001b[0m                 \"Reshape your data either using array.reshape(-1, 1) if \"\n\u001b[0;32m   1047\u001b[0m                 \"your data has a single feature or array.reshape(1, -1) \"\n\u001b[0;32m   1048\u001b[0m                 \"if it contains a single sample.\"\n\u001b[1;32m-> 1049\u001b[0m             )\n\u001b[0;32m   1050\u001b[0m         raise ValueError(msg)\n\u001b[0;32m   1052\u001b[0m if dtype_numeric and hasattr(array.dtype, \"kind\") and array.dtype.kind in \"USV\":\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    123\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    124\u001b[0m     X,\n\u001b[0;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m--> 126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    130\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m             )\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[0;32m    176\u001b[0m     X,\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    178\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    179\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    181\u001b[0m ):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    Test failed: Array contains non-finite values.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     _assert_all_finite(\n\u001b[0;32m    214\u001b[0m         X\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X) \u001b[38;5;28;01melse\u001b[39;00m X,\n\u001b[0;32m    215\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    216\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    217\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), #9\n",
    "    'optimizer':(0,7), #7\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (100, 500), #(10, 50), #\n",
    "    'epochs':(20, 40),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) #25\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8e3b91a4-8293-4cad-a359-1bd8f3da8fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 230,\n",
       " 'dropout': 0.7296061783380641,\n",
       " 'dropout_rate': 0.19126724140656393,\n",
       " 'epochs': 38,\n",
       " 'kernel': 1.9444298503238986,\n",
       " 'layers1': 1,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.7631771981307285,\n",
       " 'neurons': 61,\n",
       " 'normalization': 0.770967179954561,\n",
       " 'optimizer': <keras.src.optimizers.adadelta.Adadelta at 0x245c6f28740>}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU, 'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'Adam']\n",
    "optimizerD = {\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate)\n",
    "}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ffa562-44de-45fa-9ad1-913a75af66d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Running CNN with Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d7a06a47-8391-444e-ab8b-58a4386dba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model with optimized hyperparameters\n",
    "\n",
    "epochs = 38\n",
    "batch_size = 230\n",
    "\n",
    "timesteps = len(X_train[0])  \n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15\n",
    "\n",
    "layers1 = 1\n",
    "layers2 = 2\n",
    "activation = 'softsign'\n",
    "kernel = int(round(1.9444298503238986))  \n",
    "neurons = 61\n",
    "normalization = 0.770967179954561  \n",
    "dropout = 0.7296061783380641  \n",
    "dropout_rate = 0.19126724140656393  \n",
    "optimizer = Adadelta(learning_rate=0.7631771981307285) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Add second set of dense layers\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(MaxPooling1D())  # Max-pooling layer to downsample the data\n",
    "model.add(Flatten())  # Flatten for the dense layers\n",
    "model.add(Dense(n_classes, activation='softmax'))  # Output layer for classification\n",
    "\n",
    "# Compile the model with specified loss and optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "317f469b-51ed-43ca-a631-3999122e7b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_76\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_76\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,159</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_384 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_385 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_386 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,782</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_387 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,420</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_76 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │         \u001b[38;5;34m1,159\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │           \u001b[38;5;34m244\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_384 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │         \u001b[38;5;34m3,782\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_385 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │         \u001b[38;5;34m3,782\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_386 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │         \u001b[38;5;34m3,782\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_76 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m61\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_76 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m427\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_387 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m6,420\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,169</span> (74.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,169\u001b[0m (74.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,047</span> (74.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,047\u001b[0m (74.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122</span> (488.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m122\u001b[0m (488.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ff3adc60-3456-4445-8974-fe1acddc7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "75/75 - 3s - 45ms/step - accuracy: 0.6682 - loss: 1.1192\n",
      "Epoch 2/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.7253 - loss: 0.8134\n",
      "Epoch 3/38\n",
      "75/75 - 1s - 12ms/step - accuracy: 0.7519 - loss: 0.7304\n",
      "Epoch 4/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.7671 - loss: 0.6807\n",
      "Epoch 5/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.7821 - loss: 0.6329\n",
      "Epoch 6/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.7950 - loss: 0.6015\n",
      "Epoch 7/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8057 - loss: 0.5688\n",
      "Epoch 8/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8141 - loss: 0.5349\n",
      "Epoch 9/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8234 - loss: 0.5107\n",
      "Epoch 10/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8285 - loss: 0.4964\n",
      "Epoch 11/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8408 - loss: 0.4652\n",
      "Epoch 12/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8431 - loss: 0.4544\n",
      "Epoch 13/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8509 - loss: 0.4341\n",
      "Epoch 14/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8573 - loss: 0.4152\n",
      "Epoch 15/38\n",
      "75/75 - 1s - 12ms/step - accuracy: 0.8601 - loss: 0.4078\n",
      "Epoch 16/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8691 - loss: 0.3858\n",
      "Epoch 17/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8683 - loss: 0.3774\n",
      "Epoch 18/38\n",
      "75/75 - 1s - 17ms/step - accuracy: 0.8781 - loss: 0.3575\n",
      "Epoch 19/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8800 - loss: 0.3504\n",
      "Epoch 20/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8829 - loss: 0.3391\n",
      "Epoch 21/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8833 - loss: 0.3378\n",
      "Epoch 22/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8900 - loss: 0.3216\n",
      "Epoch 23/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.8918 - loss: 0.3143\n",
      "Epoch 24/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.8933 - loss: 0.3091\n",
      "Epoch 25/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.9004 - loss: 0.2940\n",
      "Epoch 26/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.9025 - loss: 0.2875\n",
      "Epoch 27/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.9006 - loss: 0.2893\n",
      "Epoch 28/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.9001 - loss: 0.2860\n",
      "Epoch 29/38\n",
      "75/75 - 1s - 14ms/step - accuracy: 0.9039 - loss: 0.2776\n",
      "Epoch 30/38\n",
      "75/75 - 1s - 12ms/step - accuracy: 0.9087 - loss: 0.2680\n",
      "Epoch 31/38\n",
      "75/75 - 1s - 12ms/step - accuracy: 0.9097 - loss: 0.2628\n",
      "Epoch 32/38\n",
      "75/75 - 1s - 15ms/step - accuracy: 0.9134 - loss: 0.2498\n",
      "Epoch 33/38\n",
      "75/75 - 1s - 11ms/step - accuracy: 0.9148 - loss: 0.2539\n",
      "Epoch 34/38\n",
      "75/75 - 1s - 13ms/step - accuracy: 0.9169 - loss: 0.2437\n",
      "Epoch 35/38\n",
      "75/75 - 1s - 12ms/step - accuracy: 0.9151 - loss: 0.2450\n",
      "Epoch 36/38\n",
      "75/75 - 1s - 20ms/step - accuracy: 0.9138 - loss: 0.2444\n",
      "Epoch 37/38\n",
      "75/75 - 1s - 16ms/step - accuracy: 0.9191 - loss: 0.2377\n",
      "Epoch 38/38\n",
      "75/75 - 1s - 15ms/step - accuracy: 0.9212 - loss: 0.2281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x245c7282cc0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc15a6-5126-4589-83be-48501d1f6b73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9f808700-6cec-4f78-b9c1-118680d74e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of stations names\n",
    "\n",
    "stations = {\n",
    "0: 'BASEL',\n",
    "1: 'BELGRADE',\n",
    "2: 'BUDAPEST',\n",
    "3: 'DEBILT',\n",
    "4: 'DUSSELDORF',\n",
    "5: 'HEATHROW',\n",
    "6: 'KASSEL',\n",
    "7: 'LJUBLJANA',\n",
    "8: 'MAASTRICHT',\n",
    "9: 'MADRID',\n",
    "10: 'MUNCHENB',\n",
    "11: 'OSLO',\n",
    "12: 'SONNBLICK',\n",
    "13: 'STOCKHOLM',\n",
    "14: 'VALENTIA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d24bb997-e705-45b6-a515-a3fee7fe2f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 91.50%\n"
     ]
    }
   ],
   "source": [
    "# Predict the class probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert y_test and y_pred to class labels\n",
    "if y_test_one_hot.ndim == 1:\n",
    "    y_test_labels = y_test_one_hot\n",
    "else:\n",
    "    y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "if y_pred.ndim == 1:\n",
    "    y_pred_labels = y_pred\n",
    "else:\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Manually calculate accuracy\n",
    "correct_predictions = np.sum(y_test_labels == y_pred_labels)\n",
    "total_samples = len(y_test_labels)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "48848c26-33ce-49be-9158-e14025f75fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before making predictions, convert y_test to one-hot format\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "68eea63c-0301-4eca-9e93-9136c4874994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  DUSSELDORF  HEATHROW  KASSEL  \\\n",
      "True                                                                          \n",
      "BASEL        3556        73        12      10           5         5       0   \n",
      "BELGRADE       75       983        12       4           0         3       0   \n",
      "BUDAPEST       22        16       155       6           1         4       0   \n",
      "DEBILT          7         4         9      58           2         2       0   \n",
      "DUSSELDORF      1         0         1       2          12         7       0   \n",
      "HEATHROW       12         1         0       1           2        36       0   \n",
      "KASSEL          1         1         1       0           2         0       3   \n",
      "LJUBLJANA       6         1         3       0           0         0       0   \n",
      "MAASTRICHT      6         0         0       0           0         0       0   \n",
      "MADRID         41         3         9       0           0         1       0   \n",
      "MUNCHENB        7         0         0       0           0         0       0   \n",
      "OSLO            0         0         0       0           0         0       0   \n",
      "STOCKHOLM       2         0         0       0           0         0       0   \n",
      "VALENTIA        1         0         0       0           0         0       0   \n",
      "\n",
      "Pred        LJUBLJANA  MAASTRICHT  MADRID  MUNCHENB  OSLO  \n",
      "True                                                       \n",
      "BASEL               0           0      21         0     0  \n",
      "BELGRADE            4           0      11         0     0  \n",
      "BUDAPEST            1           0       9         0     0  \n",
      "DEBILT              0           0       0         0     0  \n",
      "DUSSELDORF          1           0       5         0     0  \n",
      "HEATHROW            1           0      27         0     2  \n",
      "KASSEL              0           1       1         1     0  \n",
      "LJUBLJANA          37           0      13         0     1  \n",
      "MAASTRICHT          0           2       1         0     0  \n",
      "MADRID              2           0     402         0     0  \n",
      "MUNCHENB            0           0       0         1     0  \n",
      "OSLO                0           0       0         0     5  \n",
      "STOCKHOLM           0           0       0         1     1  \n",
      "VALENTIA            0           0       0         0     0  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(confusion_matrix(y_test_one_hot, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881963e-7490-4a68-8a50-9b9d96566008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
